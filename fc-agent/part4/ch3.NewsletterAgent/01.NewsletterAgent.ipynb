{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newsletter Agent의 노드 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자가 입력한 키워드에 대한 뉴스 검색 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient()\n",
    "\n",
    "def search_recent_news(keyword):\n",
    "    \"\"\"\n",
    "    This tool interacts with the Tavily AI API to search for recent news articles related to a given keyword.\n",
    "\n",
    "    Args:\n",
    "        keyword (str): The keyword or phrase to search for in the news articles.\n",
    "\n",
    "    Returns:\n",
    "        list: \n",
    "        A list of titles, each containing up to 10 of the most recent news articles related to the keyword.\n",
    "        - 'title' (str): The title of the news article.\n",
    "\n",
    "    Example:\n",
    "        response = search_news(\"OpenAI\")\n",
    "        # Returns a list of news articles published in the last day related to OpenAI.\n",
    "    \"\"\"\n",
    "    article_info = []\n",
    "    \n",
    "    # Making the request to the Tavily API\n",
    "    response = tavily_client.search(\n",
    "        query=keyword, \n",
    "        max_results=10, \n",
    "        topic=\"news\", \n",
    "        days=7\n",
    "    )\n",
    "    title_list = [i['title'] for i in response['results']]\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenAI is making its own browser, presumably to spite Google and cut out the middleman when collecting user data - PC Gamer',\n",
       " 'OpenAI Hits Pause on Open-Source Model: Safety First! - OpenTools',\n",
       " 'OpenAI delays the release of its open model, again - TechCrunch',\n",
       " '$300 billion, 500 million users, and no time to enjoy it: The sharks are circling OpenAI - Business Insider Africa',\n",
       " \"Microsoft's Existing OpenAI Deal May Be Undercutting Ad Agency Partnerships - Adweek\",\n",
       " 'OpenAI tightens the screws on security to keep away prying eyes - TechCrunch',\n",
       " 'Google scuppers $3bn OpenAI deal by buying key technology and developers - Gagadget.com',\n",
       " 'Sam Altman says OpenAI is delaying its open-weight model to run extra safety tests - Business Insider',\n",
       " 'ChatGPT keeps having more memories of you - Axios',\n",
       " 'OpenAI’s Windsurf deal is off — and Windsurf’s CEO is going to Google - The Verge']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword = \"OpenAI\"\n",
    "result = search_recent_news(keyword)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 테마 설정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)\n",
    "\n",
    "# Data model\n",
    "class NewsletterThemeOutput(BaseModel):\n",
    "    \"\"\"Output model for structured theme and sub-theme generation.\"\"\"\n",
    "\n",
    "    theme: str = Field(\n",
    "        description=\"The main newsletter theme based on the provided article titles.\"\n",
    "    )\n",
    "    sub_themes: list[str] = Field(\n",
    "        description=\"List of sub-themes or key news items to investigate under the main theme, ensuring they are specific and researchable.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_newsletter = llm.with_structured_output(NewsletterThemeOutput)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "You are an expert helping to create a newsletter. \n",
    "Based on a list of article titles provided, your task is to choose a single, \n",
    "specific newsletter theme framed as a clear, detailed question that grabs the reader's attention. \n",
    "\n",
    "In addition, generate 5 sub-themes that are highly specific, researchable news items or insights under the main theme. \n",
    "Ensure these sub-themes reflect the latest trends in the field and frame them as compelling news topics.\n",
    "\n",
    "The output should be formatted as:\n",
    "- Main theme (in question form)\n",
    "- 3-5 sub-themes (detailed and focused on emerging trends, technologies, or insights).\n",
    "\n",
    "The sub-themes should create a clear direction for the newsletter, avoiding broad, generic topics.\n",
    "All your output should be in Korean\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# This is the template that will feed into the structured LLM\n",
    "theme_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Article titles: \\n\\n {article_titles}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain together the system prompt and the structured output model\n",
    "newsletter_generator = theme_prompt | structured_llm_newsletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenAI의 독자 브라우저 개발: Google에 대한 반격과 사용자 데이터 수집의 직접화',\n",
       " '안전성을 최우선 과제로 삼은 OpenAI의 오픈소스 모델 지연 이유 분석',\n",
       " 'OpenAI가 마주한 시장의 압박: 3000억 달러, 5억 사용자의 미래는?',\n",
       " 'Microsoft의 OpenAI와의 협약이 광고 대행사 파트너십에 미치는 영향',\n",
       " 'OpenAI의 보안 강화 조치: 외부의 위협으로부터 어떻게 방어하고 있는가?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = newsletter_generator.invoke({\"article_titles\":result})\n",
    "subthemes = output.sub_themes\n",
    "subthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def subtheme_generator(recent_news: List[str]):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)\n",
    "\n",
    "    # Data model\n",
    "    class NewsletterThemeOutput(BaseModel):\n",
    "        \"\"\"Output model for structured theme and sub-theme generation.\"\"\"\n",
    "\n",
    "        theme: str = Field(\n",
    "            description=\"The main newsletter theme based on the provided article titles.\"\n",
    "        )\n",
    "        sub_themes: list[str] = Field(\n",
    "            description=\"List of sub-themes or key news items to investigate under the main theme, ensuring they are specific and researchable.\"\n",
    "        )\n",
    "    # LLM with function call\n",
    "    structured_llm_newsletter = llm.with_structured_output(NewsletterThemeOutput)\n",
    "\n",
    "    # Prompt\n",
    "    system = \"\"\"\n",
    "    You are an expert helping to create a newsletter. Based on a list of article titles provided, your task is to choose a single, \n",
    "    specific newsletter theme framed as a clear, detailed question that grabs the reader's attention. \n",
    "\n",
    "    In addition, generate 3 to 5 sub-themes that are highly specific, researchable news items or insights under the main theme. \n",
    "    Ensure these sub-themes reflect the latest trends in the field and frame them as compelling news topics.\n",
    "\n",
    "    The output should be formatted as:\n",
    "    - Main theme (in question form)\n",
    "    - 3-5 sub-themes (detailed and focused on emerging trends, technologies, or insights).\n",
    "\n",
    "    The sub-themes should create a clear direction for the newsletter, avoiding broad, generic topics.\n",
    "    All your output should be in Korean\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # This is the template that will feed into the structured LLM\n",
    "    theme_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Article titles: \\n\\n {recent_news}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Chain together the system prompt and the structured output model\n",
    "    subtheme_chain= theme_prompt | structured_llm_newsletter\n",
    "    output = subtheme_chain.invoke({\"recent_news\":recent_news})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewsletterThemeOutput(theme='OpenAI의 현재 상황은 무엇이며, 이를 통해 우리가 배울 수 있는 점은 무엇인가?', sub_themes=['OpenAI가 자사 브라우저를 개발하는 이유: 구글과의 경쟁 구도 분석', 'OpenAI의 오픈 소스 모델 지연, 안전성 우선 과제가 드러난 배경', 'OpenAI와 마이크로소프트의 파트너십이 광고 산업에 미치는 영향', 'OpenAI의 보안 강화 조치: 사용자 데이터 보호를 위한 새로운 전략', 'OpenAI의 전략적 결정 변화: Windsurf 거래 중단의 의미와 미래 전망'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = subtheme_generator({\"article_titles\":result})\n",
    "subthemes = output.sub_themes\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fc-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
