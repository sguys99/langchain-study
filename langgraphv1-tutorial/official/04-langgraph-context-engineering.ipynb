{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain Context Engineering\n",
        "\n",
        "에이전트를 구축하는 데 있어 가장 어려운 부분은 충분히 신뢰할 수 있게 만드는 것입니다. 프로토타입에서는 작동하지만, 실제 사용 사례에서는 종종 실패합니다.\n",
        "\n",
        "## 에이전트가 실패하는 이유\n",
        "\n",
        "에이전트가 실패할 때는 일반적으로 에이전트 내부의 LLM 호출이 잘못된 작업을 수행하거나 예상대로 작동하지 않았기 때문입니다. LLM은 다음 두 가지 이유 중 하나로 실패합니다:\n",
        "\n",
        "1. 기본 LLM이 충분히 능력이 없음\n",
        "2. \"올바른\" 컨텍스트가 LLM에 전달되지 않음\n",
        "\n",
        "대부분의 경우 실제로는 두 번째 이유가 에이전트의 신뢰성을 떨어뜨립니다.\n",
        "\n",
        "**Context Engineering**은 LLM이 작업을 완수할 수 있도록 올바른 형식으로 올바른 정보와 도구를 제공하는 것입니다. 이것이 AI 엔지니어의 가장 중요한 업무입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 사전 준비\n",
        "\n",
        "환경 변수를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_teddynote import logging\n",
        "\n",
        "logging.langsmith(\"LangChain-V1-Tutorial\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 컨텍스트의 종류\n",
        "\n",
        "에이전트는 세 가지 종류의 컨텍스트를 제어합니다:\n",
        "\n",
        "| 컨텍스트 타입 | 제어 대상 | 지속성 |\n",
        "|------------|---------|-------|\n",
        "| **Model Context** | 모델 호출에 들어가는 내용 (지시사항, 메시지 기록, 도구, 응답 형식) | Transient |\n",
        "| **Tool Context** | 도구가 액세스하고 생성하는 내용 (상태, 저장소, 런타임 컨텍스트에 읽기/쓰기) | Persistent |\n",
        "| **Life-cycle Context** | 모델 및 도구 호출 사이에 발생하는 작업 (요약, 가드레일, 로깅 등) | Persistent |\n",
        "\n",
        "**Transient Context**: LLM이 단일 호출에서 보는 내용. 상태에 저장된 내용을 변경하지 않고 메시지, 도구 또는 프롬프트를 수정할 수 있습니다.\n",
        "\n",
        "**Persistent Context**: 여러 턴에 걸쳐 상태에 저장되는 내용. 라이프사이클 훅과 도구 쓰기는 이를 영구적으로 수정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 소스\n",
        "\n",
        "에이전트는 다양한 데이터 소스에 액세스(읽기/쓰기)합니다:\n",
        "\n",
        "| 데이터 소스 | 다른 이름 | 범위 | 예시 |\n",
        "|----------|---------|------|-----|\n",
        "| **Runtime Context** | 정적 구성 | 대화 범위 | 사용자 ID, API 키, DB 연결, 권한 |\n",
        "| **State** | 단기 메모리 | 대화 범위 | 현재 메시지, 업로드된 파일, 인증 상태 |\n",
        "| **Store** | 장기 메모리 | 대화 간 공유 | 사용자 선호도, 추출된 인사이트, 기록 데이터 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Context\n",
        "\n",
        "각 모델 호출에 들어가는 내용을 제어합니다 - 지시사항, 사용 가능한 도구, 사용할 모델 및 출력 형식입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### System Prompt\n",
        "\n",
        "시스템 프롬프트는 LLM의 동작과 능력을 설정합니다. 다양한 사용자, 컨텍스트 또는 대화 단계에는 다양한 지시사항이 필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### State 기반 System Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_tool(query: str) -> str:\n",
        "    \"\"\"Search for information.\"\"\"\n",
        "    return f\"Results for: {query}\"\n",
        "\n",
        "\n",
        "@dynamic_prompt\n",
        "def state_aware_prompt(request: ModelRequest) -> str:\n",
        "    \"\"\"State의 메시지 수에 따라 프롬프트 조정\"\"\"\n",
        "    # request.messages는 request.state[\"messages\"]의 단축형\n",
        "    message_count = len(request.messages)\n",
        "\n",
        "    base = \"You are a helpful assistant.\"\n",
        "\n",
        "    if message_count > 10:\n",
        "        base += \"\\nThis is a long conversation - be extra concise.\"\n",
        "\n",
        "    return base\n",
        "\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "agent = create_agent(model=model, tools=[search_tool], middleware=[state_aware_prompt])\n",
        "\n",
        "# 짧은 대화\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})\n",
        "print(\"Short conversation:\", result[\"messages\"][-1].content[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Store 기반 System Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain_teddynote.messages import invoke_graph, stream_graph\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_id: str\n",
        "\n",
        "\n",
        "@dynamic_prompt\n",
        "def store_aware_prompt(request: ModelRequest) -> str:\n",
        "    \"\"\"Store에서 사용자 선호도를 가져와서 프롬프트 조정\"\"\"\n",
        "    user_id = request.runtime.context.user_id\n",
        "\n",
        "    # Store에서 사용자 선호도 읽기\n",
        "    store = request.runtime.store\n",
        "    user_prefs = store.get((\"preferences\",), user_id)\n",
        "\n",
        "    base = \"You are a helpful assistant.\"\n",
        "\n",
        "    if user_prefs:\n",
        "        style = user_prefs.value.get(\"communication_style\", \"\")\n",
        "        base += f\"\\nUser prefers {style} responses.\"\n",
        "        print(f\"User prefers {style} responses.\")\n",
        "    else:\n",
        "        base += \"\\nUser prefers professional tone. Answer in 3 sentences.\"\n",
        "\n",
        "    return base\n",
        "\n",
        "\n",
        "# Store 생성 및 초기화\n",
        "store = InMemoryStore()\n",
        "store.put(\n",
        "    (\"preferences\",),\n",
        "    \"teddy\",\n",
        "    {\n",
        "        \"communication_style\": \"아주 간결하고 emoji 를 사용하여 친근감 있는 스타일. bullet point 로 정리된 답변.\"\n",
        "    },\n",
        ")\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[search_tool],\n",
        "    middleware=[store_aware_prompt],\n",
        "    context_schema=Context,\n",
        "    store=store,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_id: teddy\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\n",
        "        \"messages\": [HumanMessage(content=\"머신러닝의 동작 원리에 대해서 설명해줘\")]\n",
        "    },\n",
        "    context=Context(user_id=\"teddy\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_id: other\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\n",
        "        \"messages\": [HumanMessage(content=\"머신러닝의 동작 원리에 대해서 설명해줘\")]\n",
        "    },\n",
        "    context=Context(user_id=\"other\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Runtime Context 기반 System Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class RoleContext:\n",
        "    user_role: str\n",
        "    deployment_env: str\n",
        "\n",
        "\n",
        "@dynamic_prompt\n",
        "def context_aware_prompt(request: ModelRequest) -> str:\n",
        "    \"\"\"Runtime Context에서 사용자 역할과 환경을 기반으로 프롬프트 조정\"\"\"\n",
        "    user_role = request.runtime.context.user_role\n",
        "    env = request.runtime.context.deployment_env\n",
        "\n",
        "    base = \"You are a helpful assistant.\"\n",
        "\n",
        "    if user_role == \"admin\":\n",
        "        base += \"\\nYou have admin access. You can perform all operations.\"\n",
        "    elif user_role == \"viewer\":\n",
        "        base += \"\\nYou have read-only access. Guide users to read operations only.\"\n",
        "\n",
        "    if env == \"production\":\n",
        "        base += \"\\nBe extra careful with any data modifications.\"\n",
        "    print(f\"User role: {user_role}, Deployment environment: {env}\")\n",
        "    return base\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[search_tool],\n",
        "    middleware=[context_aware_prompt],\n",
        "    context_schema=RoleContext,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Admin 사용자\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\"messages\": [HumanMessage(content=\"데이터 추가가 가능한가요?\")]},\n",
        "    context=RoleContext(user_role=\"admin\", deployment_env=\"production\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# viewer 사용자\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\"messages\": [HumanMessage(content=\"데이터 추가가 가능한가요?\")]},\n",
        "    context=RoleContext(user_role=\"viewer\", deployment_env=\"production\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Messages\n",
        "\n",
        "메시지는 LLM에 전송되는 프롬프트를 구성합니다. LLM이 올바른 정보를 가지고 잘 응답할 수 있도록 메시지 내용을 관리하는 것이 중요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### State에서 파일 컨텍스트 주입"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import wrap_model_call, ModelResponse\n",
        "from typing import Callable\n",
        "\n",
        "\n",
        "@wrap_model_call\n",
        "def inject_file_context(\n",
        "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
        ") -> ModelResponse:\n",
        "    \"\"\"사용자가 업로드한 파일 컨텍스트를 주입\"\"\"\n",
        "    # State에서 업로드된 파일 메타데이터 가져오기\n",
        "    uploaded_files = request.state.get(\"uploaded_files\", [])\n",
        "\n",
        "    if uploaded_files:\n",
        "        # 사용 가능한 파일에 대한 컨텍스트 구축\n",
        "        file_descriptions = []\n",
        "        for file in uploaded_files:\n",
        "            file_descriptions.append(\n",
        "                f\"- {file['name']} ({file['type']}): {file['summary']}\"\n",
        "            )\n",
        "\n",
        "        file_context = f\"\"\"Files you have access to in this conversation:\n",
        "{chr(10).join(file_descriptions)}\n",
        "\n",
        "Reference these files when answering questions.\"\"\"\n",
        "\n",
        "        # 최근 메시지 앞에 파일 컨텍스트 주입\n",
        "        messages = [\n",
        "            *request.messages,\n",
        "            {\"role\": \"user\", \"content\": file_context},\n",
        "        ]\n",
        "        request = request.override(messages=messages)\n",
        "\n",
        "    return handler(request)\n",
        "\n",
        "\n",
        "agent = create_agent(model=model, tools=[search_tool], middleware=[inject_file_context])\n",
        "\n",
        "# 파일이 업로드된 상태로 호출\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"What files do I have?\"}],\n",
        "        \"uploaded_files\": [\n",
        "            {\"name\": \"report.pdf\", \"type\": \"PDF\", \"summary\": \"Q4 sales report\"},\n",
        "            {\"name\": \"data.csv\", \"type\": \"CSV\", \"summary\": \"Customer data\"},\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tools\n",
        "\n",
        "도구를 통해 모델이 데이터베이스, API 및 외부 시스템과 상호 작용할 수 있습니다. 도구를 정의하고 선택하는 방법은 모델이 작업을 효과적으로 완료할 수 있는지에 직접적인 영향을 미칩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 도구 정의\n",
        "\n",
        "각 도구에는 명확한 이름, 설명, 인수 이름 및 인수 설명이 필요합니다. 이것들은 단순한 메타데이터가 아니라 모델이 도구를 언제 어떻게 사용할지에 대한 추론을 안내합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "@tool(parse_docstring=True)\n",
        "def search_orders(user_id: str, status: str, limit: int = 10) -> str:\n",
        "    \"\"\"Search for user orders by status.\n",
        "\n",
        "    Use this when the user asks about order history or wants to check\n",
        "    order status. Always filter by the provided status.\n",
        "\n",
        "    Args:\n",
        "        user_id: Unique identifier for the user\n",
        "        status: Order status: 'pending', 'shipped', or 'delivered'\n",
        "        limit: Maximum number of results to return\n",
        "    \"\"\"\n",
        "    return f\"Found orders for {user_id} with status {status} (limit: {limit})\"\n",
        "\n",
        "\n",
        "agent = create_agent(model=model, tools=[search_orders])\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": \"Show me my pending orders for user_123\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### State 기반 도구 선택\n",
        "\n",
        "대화 단계에 따라 사용 가능한 도구를 동적으로 조정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def public_search(query: str) -> str:\n",
        "    \"\"\"Public search - available to all users.\"\"\"\n",
        "    return f\"Public results for: {query}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def private_search(query: str) -> str:\n",
        "    \"\"\"Private search - requires authentication.\"\"\"\n",
        "    return f\"Private results for: {query}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def advanced_search(query: str) -> str:\n",
        "    \"\"\"Advanced search - requires authentication and conversation history.\"\"\"\n",
        "    return f\"Advanced results for: {query}\"\n",
        "\n",
        "\n",
        "@wrap_model_call\n",
        "def state_based_tools(\n",
        "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
        ") -> ModelResponse:\n",
        "    \"\"\"대화 State에 따라 도구 필터링\"\"\"\n",
        "    state = request.state\n",
        "    is_authenticated = state.get(\"authenticated\", False)\n",
        "    message_count = len(state[\"messages\"])\n",
        "\n",
        "    # 인증되지 않은 경우 공개 도구만 활성화\n",
        "    if not is_authenticated:\n",
        "        tools = [t for t in request.tools if t.name == \"public_search\"]\n",
        "        request = request.override(tools=tools)\n",
        "    elif message_count < 5:\n",
        "        # 대화 초반에는 고급 도구 제한\n",
        "        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n",
        "        request = request.override(tools=tools)\n",
        "\n",
        "    return handler(request)\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[public_search, private_search, advanced_search],\n",
        "    middleware=[state_based_tools],\n",
        ")\n",
        "\n",
        "# 인증되지 않은 사용자\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for Python tutorials\"}],\n",
        "        \"authenticated\": False,\n",
        "    }\n",
        ")\n",
        "print(\"Unauthenticated:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# 인증된 사용자\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for Python tutorials\"}],\n",
        "        \"authenticated\": True,\n",
        "    }\n",
        ")\n",
        "print(\"\\nAuthenticated:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Runtime Context 기반 도구 선택\n",
        "\n",
        "사용자 권한에 따라 도구를 필터링합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def read_data(table: str) -> str:\n",
        "    \"\"\"테이블에서 데이터를 읽어옵니다.\"\"\"\n",
        "    return f\"{table} 테이블에서 데이터를 읽었습니다.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def write_data(table: str) -> str:\n",
        "    \"\"\"테이블에 데이터를 작성합니다.\"\"\"\n",
        "    return f\"{table} 테이블에 데이터를 작성했습니다.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def delete_data(table: str, data_id: str) -> str:\n",
        "    \"\"\"테이블에서 데이터를 삭제합니다.\"\"\"\n",
        "    return f\"{table} 테이블에서 데이터를 삭제했습니다.\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class UserRole:\n",
        "    user_role: str\n",
        "\n",
        "\n",
        "@wrap_model_call\n",
        "def context_based_tools(\n",
        "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
        ") -> ModelResponse:\n",
        "    \"\"\"Runtime Context 권한에 따라 도구 필터링\"\"\"\n",
        "    user_role = request.runtime.context.user_role\n",
        "\n",
        "    if user_role == \"admin\":\n",
        "        # 관리자는 모든 도구 사용 가능\n",
        "        pass\n",
        "    elif user_role == \"editor\":\n",
        "        # 편집자는 삭제 도구를 사용할 수 없습니다.\n",
        "        tools = [t for t in request.tools if t.name != \"delete_data\"]\n",
        "        request = request.override(tools=tools)\n",
        "    else:\n",
        "        # 뷰어는 읽기 전용 도구만 사용할 수 있습니다.\n",
        "        tools = [t for t in request.tools if t.name == \"read_data\"]\n",
        "        request = request.override(tools=tools)\n",
        "\n",
        "    return handler(request)\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[read_data, write_data, delete_data],\n",
        "    middleware=[context_based_tools],\n",
        "    context_schema=UserRole,\n",
        "    system_prompt=\"사용자의 요구사항을 바로 수행해 주세요. 주어진 도구를 사용해 주세요. 사용할 도구가 없다면, 권한이 없다고 답변하세요.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 뷰어\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\"messages\": [HumanMessage(content=\"User 테이블을 조회하세요.\")]},\n",
        "    context=UserRole(user_role=\"viewer\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 뷰어\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\n",
        "        \"messages\": [HumanMessage(content=\"User 테이블에서 abc 레코드를 삭제해 주세요\")]\n",
        "    },\n",
        "    context=UserRole(user_role=\"viewer\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 관리자\n",
        "stream_graph(\n",
        "    agent,\n",
        "    inputs={\n",
        "        \"messages\": [HumanMessage(content=\"User 테이블에서 abc 레코드를 삭제해 주세요\")]\n",
        "    },\n",
        "    context=UserRole(user_role=\"admin\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model\n",
        "\n",
        "다양한 모델은 다양한 강점, 비용 및 컨텍스트 창을 가지고 있습니다. 작업에 적합한 모델을 선택하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# 모델을 미들웨어 외부에서 한 번만 초기화\n",
        "large_model = init_chat_model(\"openai:gpt-4.1\")\n",
        "efficient_model = init_chat_model(\"openai:gpt-4.1-mini\")\n",
        "\n",
        "\n",
        "@wrap_model_call\n",
        "def state_based_model(\n",
        "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
        ") -> ModelResponse:\n",
        "    \"\"\"대화 길이에 따라 모델 선택\"\"\"\n",
        "    message_count = len(request.messages)\n",
        "\n",
        "    if message_count > 10:\n",
        "        # 긴 대화 - 큰 컨텍스트 창을 가진 모델 사용\n",
        "        model = large_model\n",
        "        print(f\"Using large model for {message_count} messages\")\n",
        "    else:\n",
        "        # 짧은 대화 - 효율적인 모델 사용\n",
        "        model = efficient_model\n",
        "        print(f\"Using efficient model for {message_count} messages\")\n",
        "\n",
        "    request = request.override(model=model)\n",
        "    return handler(request)\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=efficient_model, tools=[search_tool], middleware=[state_based_model]\n",
        ")\n",
        "\n",
        "# 짧은 대화\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})\n",
        "print(result[\"messages\"][-1].content[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Response Format\n",
        "\n",
        "구조화된 출력은 비구조화된 텍스트를 검증된 구조화 데이터로 변환합니다. 특정 필드를 추출하거나 다운스트림 시스템을 위한 데이터를 반환할 때 자유 형식 텍스트로는 충분하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class CustomerSupportTicket(BaseModel):\n",
        "    \"\"\"고객 메시지에서 추출된 구조화된 티켓 정보\"\"\"\n",
        "\n",
        "    category: str = Field(\n",
        "        description=\"Issue category: 'billing', 'technical', 'account', or 'product'\"\n",
        "    )\n",
        "    priority: str = Field(\n",
        "        description=\"Urgency level: 'low', 'medium', 'high', or 'critical'\"\n",
        "    )\n",
        "    summary: str = Field(description=\"One-sentence summary of the customer's issue\")\n",
        "    customer_sentiment: str = Field(\n",
        "        description=\"Customer's emotional tone: 'frustrated', 'neutral', or 'satisfied'\"\n",
        "    )\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model, tools=[search_tool], response_format=CustomerSupportTicket\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"I can't login to my account! I've been trying for an hour and it keeps saying invalid credentials.\",\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "# 결과는 CustomerSupportTicket 형식으로 반환됨\n",
        "print(\"Ticket:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### State 기반 Response Format 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleResponse(BaseModel):\n",
        "    \"\"\"초기 대화를 위한 간단한 응답\"\"\"\n",
        "\n",
        "    answer: str = Field(description=\"A brief answer\")\n",
        "\n",
        "\n",
        "class DetailedResponse(BaseModel):\n",
        "    \"\"\"확립된 대화를 위한 상세한 응답\"\"\"\n",
        "\n",
        "    answer: str = Field(description=\"A detailed answer\")\n",
        "    reasoning: str = Field(description=\"Explanation of reasoning\")\n",
        "    confidence: float = Field(description=\"Confidence score 0-1\")\n",
        "\n",
        "\n",
        "@wrap_model_call\n",
        "def state_based_output(\n",
        "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
        ") -> ModelResponse:\n",
        "    \"\"\"State에 따라 출력 형식 선택\"\"\"\n",
        "    message_count = len(request.messages)\n",
        "\n",
        "    if message_count < 3:\n",
        "        # 초기 대화 - 간단한 형식 사용\n",
        "        request = request.override(response_format=SimpleResponse)\n",
        "    else:\n",
        "        # 확립된 대화 - 상세한 형식 사용\n",
        "        request = request.override(response_format=DetailedResponse)\n",
        "\n",
        "    return handler(request)\n",
        "\n",
        "\n",
        "agent = create_agent(model=model, tools=[search_tool], middleware=[state_based_output])\n",
        "\n",
        "# 첫 번째 메시지 - 간단한 응답\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is Python?\"}]})\n",
        "print(\"Simple response:\", result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool Context\n",
        "\n",
        "도구는 컨텍스트를 읽고 쓰는 두 가지 작업을 모두 수행합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reads - State에서 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool, ToolRuntime\n",
        "\n",
        "\n",
        "@tool\n",
        "def check_authentication(runtime: ToolRuntime) -> str:\n",
        "    \"\"\"Check if user is authenticated.\"\"\"\n",
        "    # State에서 현재 인증 상태 확인\n",
        "    current_state = runtime.state\n",
        "    is_authenticated = current_state.get(\"authenticated\", False)\n",
        "\n",
        "    if is_authenticated:\n",
        "        return \"User is authenticated\"\n",
        "    else:\n",
        "        return \"User is not authenticated\"\n",
        "\n",
        "\n",
        "agent = create_agent(model=model, tools=[check_authentication])\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Am I authenticated?\"}],\n",
        "        \"authenticated\": True,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reads - Store에서 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Context:\n",
        "    user_id: str\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_preference(preference_key: str, runtime: ToolRuntime[Context]) -> str:\n",
        "    \"\"\"Get user preference from Store.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    # Store에서 기존 선호도 읽기\n",
        "    store = runtime.store\n",
        "    existing_prefs = store.get((\"preferences\",), user_id)\n",
        "\n",
        "    if existing_prefs:\n",
        "        value = existing_prefs.value.get(preference_key)\n",
        "        return (\n",
        "            f\"{preference_key}: {value}\"\n",
        "            if value\n",
        "            else f\"No preference set for {preference_key}\"\n",
        "        )\n",
        "    else:\n",
        "        return \"No preferences found\"\n",
        "\n",
        "\n",
        "store = InMemoryStore()\n",
        "store.put((\"preferences\",), \"user_123\", {\"theme\": \"dark\", \"language\": \"ko\"})\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model, tools=[get_preference], context_schema=Context, store=store\n",
        ")\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my theme preference?\"}]},\n",
        "    context=Context(user_id=\"user_123\"),\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Writes - State에 쓰기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.types import Command\n",
        "\n",
        "\n",
        "@tool\n",
        "def authenticate_user(password: str, runtime: ToolRuntime) -> Command:\n",
        "    \"\"\"Authenticate user and update State.\"\"\"\n",
        "    # 인증 수행 (단순화됨)\n",
        "    if password == \"correct\":\n",
        "        # Command를 사용하여 State에 인증 상태 기록\n",
        "        return Command(update={\"authenticated\": True})\n",
        "    else:\n",
        "        return Command(update={\"authenticated\": False})\n",
        "\n",
        "\n",
        "agent = create_agent(model=model, tools=[authenticate_user, check_authentication])\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Authenticate with password 'correct' then check my status\",\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content)\n",
        "print(\"Authenticated in state:\", result.get(\"authenticated\", False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Writes - Store에 쓰기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def save_preference(\n",
        "    preference_key: str, preference_value: str, runtime: ToolRuntime[Context]\n",
        ") -> str:\n",
        "    \"\"\"Save user preference to Store.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "\n",
        "    # 기존 선호도 읽기\n",
        "    store = runtime.store\n",
        "    existing_prefs = store.get((\"preferences\",), user_id)\n",
        "\n",
        "    # 새 선호도와 병합\n",
        "    prefs = existing_prefs.value if existing_prefs else {}\n",
        "    prefs[preference_key] = preference_value\n",
        "\n",
        "    # Store에 업데이트된 선호도 저장\n",
        "    store.put((\"preferences\",), user_id, prefs)\n",
        "\n",
        "    return f\"Saved preference: {preference_key} = {preference_value}\"\n",
        "\n",
        "\n",
        "store = InMemoryStore()\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[save_preference, get_preference],\n",
        "    context_schema=Context,\n",
        "    store=store,\n",
        ")\n",
        "\n",
        "# 선호도 저장\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Set my theme to dark\"}]},\n",
        "    context=Context(user_id=\"user_456\"),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "# 저장된 선호도 확인\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my theme?\"}]},\n",
        "    context=Context(user_id=\"user_456\"),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Life-cycle Context\n",
        "\n",
        "핵심 에이전트 단계 **사이**에서 발생하는 작업을 제어합니다 - 데이터 흐름을 가로채서 요약, 가드레일 및 로깅과 같은 교차 관심사를 구현합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarization\n",
        "\n",
        "가장 일반적인 라이프사이클 패턴 중 하나는 대화 기록이 너무 길어질 때 자동으로 압축하는 것입니다.\n",
        "\n",
        "요약은 **상태를 영구적으로 업데이트**합니다 - 오래된 메시지를 요약으로 영구적으로 대체하여 모든 향후 턴에 대해 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import SummarizationMiddleware\n",
        "\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[search_tool],\n",
        "    middleware=[\n",
        "        SummarizationMiddleware(\n",
        "            model=\"openai:gpt-4.1-mini\",\n",
        "            max_tokens_before_summary=4000,  # 4000 토큰에서 요약 트리거\n",
        "            messages_to_keep=20,  # 요약 후 최근 20개 메시지 유지\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# 대화가 길어지면 자동으로 요약됨\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about Python\"}]}\n",
        ")\n",
        "\n",
        "print(result[\"messages\"][-1].content[:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 종합 예제: 다층 컨텍스트 엔지니어링\n",
        "\n",
        "모든 컨텍스트 엔지니어링 기술을 결합한 실용적인 예제입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import (\n",
        "    dynamic_prompt,\n",
        "    wrap_model_call,\n",
        "    ModelRequest,\n",
        "    ModelResponse,\n",
        ")\n",
        "from langchain.tools import tool, ToolRuntime\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from typing import Callable\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class UserContext:\n",
        "    user_id: str\n",
        "    user_role: str\n",
        "    subscription_tier: str\n",
        "\n",
        "\n",
        "# 도구 정의\n",
        "@tool\n",
        "def get_user_history(runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Get user's search history.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "    store = runtime.store\n",
        "\n",
        "    history = store.get((\"history\",), user_id)\n",
        "    if history:\n",
        "        return f\"Recent searches: {history.value.get('searches', [])}\"\n",
        "    return \"No history found\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def save_search(query: str, runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Save search query.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "    store = runtime.store\n",
        "\n",
        "    # 기존 히스토리 가져오기\n",
        "    existing = store.get((\"history\",), user_id)\n",
        "    searches = existing.value.get(\"searches\", []) if existing else []\n",
        "\n",
        "    # 새 검색 추가\n",
        "    searches.append(query)\n",
        "    store.put((\"history\",), user_id, {\"searches\": searches[-5:]})\n",
        "\n",
        "    return f\"Saved: {query}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def advanced_analysis(data: str, runtime: ToolRuntime[UserContext]) -> str:\n",
        "    \"\"\"Perform advanced analysis (premium feature).\"\"\"\n",
        "    tier = runtime.context.subscription_tier\n",
        "    if tier != \"premium\":\n",
        "        return \"This feature requires a premium subscription\"\n",
        "    return f\"Advanced analysis results for: {data}\"\n",
        "\n",
        "\n",
        "# 동적 시스템 프롬프트\n",
        "@dynamic_prompt\n",
        "def role_based_prompt(request: ModelRequest) -> str:\n",
        "    user_role = request.runtime.context.user_role\n",
        "    tier = request.runtime.context.subscription_tier\n",
        "\n",
        "    base = \"You are a helpful assistant.\"\n",
        "\n",
        "    if user_role == \"admin\":\n",
        "        base += \" You have admin privileges.\"\n",
        "\n",
        "    if tier == \"premium\":\n",
        "        base += \" This user has premium features enabled.\"\n",
        "\n",
        "    return base\n",
        "\n",
        "\n",
        "# 구독 등급에 따른 도구 필터링\n",
        "@wrap_model_call\n",
        "def tier_based_tools(\n",
        "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
        ") -> ModelResponse:\n",
        "    tier = request.runtime.context.subscription_tier\n",
        "\n",
        "    if tier != \"premium\":\n",
        "        # 무료 사용자는 고급 분석 불가\n",
        "        tools = [t for t in request.tools if t.name != \"advanced_analysis\"]\n",
        "        request = request.override(tools=tools)\n",
        "\n",
        "    return handler(request)\n",
        "\n",
        "\n",
        "# Store 초기화\n",
        "store = InMemoryStore()\n",
        "store.put((\"history\",), \"user_001\", {\"searches\": [\"Python\", \"Machine Learning\"]})\n",
        "\n",
        "# 에이전트 생성\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    tools=[get_user_history, save_search, advanced_analysis],\n",
        "    middleware=[\n",
        "        role_based_prompt,\n",
        "        tier_based_tools,\n",
        "    ],\n",
        "    context_schema=UserContext,\n",
        "    store=store,\n",
        ")\n",
        "\n",
        "# 테스트 1: 프리미엄 사용자\n",
        "print(\"=== Premium User ===\")\n",
        "result = agent.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"Get my search history and perform advanced analysis\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    context=UserContext(\n",
        "        user_id=\"user_001\", user_role=\"admin\", subscription_tier=\"premium\"\n",
        "    ),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)\n",
        "\n",
        "# 테스트 2: 무료 사용자\n",
        "print(\"\\n=== Free User ===\")\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Perform advanced analysis on my data\"}]},\n",
        "    context=UserContext(user_id=\"user_002\", user_role=\"user\", subscription_tier=\"free\"),\n",
        ")\n",
        "print(result[\"messages\"][-1].content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
