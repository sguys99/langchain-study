{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LangChain 단기 메모리\n",
                "\n",
                "메모리는 이전 상호작용에 대한 정보를 기억하는 시스템입니다. AI 에이전트의 경우 메모리는 이전 상호작용을 기억하고, 피드백으로부터 학습하며, 사용자 선호도에 적응할 수 있게 해주므로 매우 중요합니다.\n",
                "\n",
                "단기 메모리는 애플리케이션이 단일 스레드 또는 대화 내에서 이전 상호작용을 기억할 수 있게 해줍니다.\n",
                "\n",
                "**스레드**는 이메일이 단일 대화에서 메시지를 그룹화하는 방식과 유사하게 세션에서 여러 상호작용을 구성합니다.\n",
                "\n",
                "대화 기록은 가장 일반적인 형태의 단기 메모리입니다. 긴 대화는 오늘날의 LLM에 도전 과제를 제시합니다. 전체 기록이 LLM의 컨텍스트 창에 맞지 않아 컨텍스트 손실이나 오류가 발생할 수 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 사전 준비\n",
                "\n",
                "환경 변수를 설정합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv(override=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 기본 사용법\n",
                "\n",
                "에이전트에 단기 메모리(스레드 수준 지속성)를 추가하려면 에이전트를 생성할 때 `checkpointer`를 지정해야 합니다.\n",
                "\n",
                "LangChain의 에이전트는 단기 메모리를 에이전트 상태의 일부로 관리합니다. 그래프의 상태에 저장함으로써 에이전트는 서로 다른 스레드 간의 분리를 유지하면서 특정 대화에 대한 전체 컨텍스트에 액세스할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langgraph.checkpoint.memory import InMemorySaver\n",
                "from langchain.tools import tool\n",
                "\n",
                "# 간단한 도구 정의\n",
                "@tool\n",
                "def get_user_info(user_id: str) -> str:\n",
                "    \"\"\"Get user information.\"\"\"\n",
                "    return f\"User info for {user_id}\"\n",
                "\n",
                "# 모델 및 에이전트 생성 (체크포인터 포함)\n",
                "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_user_info],\n",
                "    checkpointer=InMemorySaver(),  # 메모리 저장소\n",
                ")\n",
                "\n",
                "# thread_id를 사용하여 대화 추적\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "# 첫 번째 메시지\n",
                "result1 = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}]},\n",
                "    config\n",
                ")\n",
                "print(\"Response 1:\", result1[\"messages\"][-1].content)\n",
                "\n",
                "# 두 번째 메시지 (이전 대화 기억)\n",
                "result2 = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
                "    config\n",
                ")\n",
                "print(\"Response 2:\", result2[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 프로덕션 환경\n",
                "\n",
                "프로덕션 환경에서는 데이터베이스를 기반으로 하는 체크포인터를 사용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PostgreSQL 체크포인터 예제 (설치 필요: pip install langgraph-checkpoint-postgres)\n",
                "# from langgraph.checkpoint.postgres import PostgresSaver\n",
                "\n",
                "# DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
                "# with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
                "#     checkpointer.setup()  # PostgreSQL에 테이블 자동 생성\n",
                "#     agent = create_agent(\n",
                "#         model=model,\n",
                "#         tools=[get_user_info],\n",
                "#         checkpointer=checkpointer,\n",
                "#     )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 에이전트 메모리 커스터마이징\n",
                "\n",
                "기본적으로 에이전트는 `AgentState`를 사용하여 단기 메모리를 관리합니다. 특히 `messages` 키를 통한 대화 기록을 관리합니다.\n",
                "\n",
                "`AgentState`를 확장하여 추가 필드를 추가할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent, AgentState\n",
                "from langgraph.checkpoint.memory import InMemorySaver\n",
                "\n",
                "# 커스텀 상태 정의\n",
                "class CustomAgentState(AgentState):\n",
                "    user_id: str\n",
                "    preferences: dict\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_user_info],\n",
                "    state_schema=CustomAgentState,  # 커스텀 상태 스키마\n",
                "    checkpointer=InMemorySaver(),\n",
                ")\n",
                "\n",
                "# 커스텀 상태를 invoke에 전달\n",
                "result = agent.invoke(\n",
                "    {\n",
                "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
                "        \"user_id\": \"user_123\",\n",
                "        \"preferences\": {\"theme\": \"dark\"}\n",
                "    },\n",
                "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
                ")\n",
                "\n",
                "print(result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 일반적인 패턴\n",
                "\n",
                "단기 메모리가 활성화된 상태에서 긴 대화는 LLM의 컨텍스트 창을 초과할 수 있습니다. 일반적인 해결책은:\n",
                "\n",
                "1. **메시지 트리밍** - 처음 또는 마지막 N개의 메시지 제거 (LLM 호출 전)\n",
                "2. **메시지 삭제** - LangGraph 상태에서 메시지를 영구적으로 삭제\n",
                "3. **메시지 요약** - 기록의 이전 메시지를 요약하고 요약으로 대체\n",
                "4. **커스텀 전략** - 메시지 필터링 등의 커스텀 전략"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 메시지 트리밍\n",
                "\n",
                "대부분의 LLM에는 최대 지원 컨텍스트 창(토큰 단위)이 있습니다. 메시지를 트리밍하는 시기를 결정하는 한 가지 방법은 메시지 기록의 토큰을 세고 한계에 접근할 때마다 트리밍하는 것입니다.\n",
                "\n",
                "에이전트에서 메시지 기록을 트리밍하려면 `@before_model` 미들웨어 데코레이터를 사용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.messages import RemoveMessage\n",
                "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
                "from langgraph.checkpoint.memory import InMemorySaver\n",
                "from langchain.agents import create_agent, AgentState\n",
                "from langchain.agents.middleware import before_model\n",
                "from langgraph.runtime import Runtime\n",
                "from typing import Any\n",
                "\n",
                "@before_model\n",
                "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "    \"\"\"컨텍스트 창에 맞도록 최근 몇 개의 메시지만 유지\"\"\"\n",
                "    messages = state[\"messages\"]\n",
                "\n",
                "    if len(messages) <= 3:\n",
                "        return None  # 변경 필요 없음\n",
                "\n",
                "    # 첫 번째 메시지와 최근 메시지만 유지\n",
                "    first_msg = messages[0]\n",
                "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
                "    new_messages = [first_msg] + recent_messages\n",
                "\n",
                "    return {\n",
                "        \"messages\": [\n",
                "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
                "            *new_messages\n",
                "        ]\n",
                "    }\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[],\n",
                "    middleware=[trim_messages],\n",
                "    checkpointer=InMemorySaver(),\n",
                ")\n",
                "\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi, my name is bob\"}]}, config)\n",
                "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"write a short poem about cats\"}]}, config)\n",
                "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"now do the same but for dogs\"}]}, config)\n",
                "final_response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]}, config)\n",
                "\n",
                "print(final_response[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 메시지 삭제\n",
                "\n",
                "그래프 상태에서 메시지를 삭제하여 메시지 기록을 관리할 수 있습니다. 특정 메시지를 제거하거나 전체 메시지 기록을 지우려는 경우에 유용합니다.\n",
                "\n",
                "그래프 상태에서 메시지를 삭제하려면 `RemoveMessage`를 사용할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.messages import RemoveMessage\n",
                "from langchain.agents import create_agent, AgentState\n",
                "from langchain.agents.middleware import after_model\n",
                "from langgraph.checkpoint.memory import InMemorySaver\n",
                "from langgraph.runtime import Runtime\n",
                "\n",
                "@after_model\n",
                "def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:\n",
                "    \"\"\"대화를 관리 가능하게 유지하기 위해 오래된 메시지 제거\"\"\"\n",
                "    messages = state[\"messages\"]\n",
                "    if len(messages) > 2:\n",
                "        # 가장 오래된 두 개의 메시지 제거\n",
                "        return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:2]]}\n",
                "    return None\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[],\n",
                "    system_prompt=\"Please be concise and to the point.\",\n",
                "    middleware=[delete_old_messages],\n",
                "    checkpointer=InMemorySaver(),\n",
                ")\n",
                "\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "# 첫 번째 메시지\n",
                "result1 = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n",
                "    config\n",
                ")\n",
                "print(\"Messages after first invoke:\", len(result1[\"messages\"]))\n",
                "\n",
                "# 두 번째 메시지\n",
                "result2 = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n",
                "    config\n",
                ")\n",
                "print(\"Messages after second invoke:\", len(result2[\"messages\"]))\n",
                "print(\"Last message:\", result2[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 메시지 요약\n",
                "\n",
                "메시지를 트리밍하거나 제거하는 문제는 메시지 큐를 제거하여 정보를 잃을 수 있다는 것입니다. 이 때문에 일부 애플리케이션은 채팅 모델을 사용하여 메시지 기록을 요약하는 더 정교한 접근 방식의 이점을 얻습니다.\n",
                "\n",
                "에이전트에서 메시지 기록을 요약하려면 내장된 `SummarizationMiddleware`를 사용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent\n",
                "from langchain.agents.middleware import SummarizationMiddleware\n",
                "from langgraph.checkpoint.memory import InMemorySaver\n",
                "\n",
                "checkpointer = InMemorySaver()\n",
                "\n",
                "agent = create_agent(\n",
                "    model=\"openai:gpt-4.1-mini\",\n",
                "    tools=[],\n",
                "    middleware=[\n",
                "        SummarizationMiddleware(\n",
                "            model=\"openai:gpt-4.1-mini\",\n",
                "            max_tokens_before_summary=4000,  # 4000 토큰에서 요약 트리거\n",
                "            messages_to_keep=20,             # 요약 후 최근 20개 메시지 유지\n",
                "        )\n",
                "    ],\n",
                "    checkpointer=checkpointer,\n",
                ")\n",
                "\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi, my name is bob\"}]}, config)\n",
                "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"write a short poem about cats\"}]}, config)\n",
                "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"now do the same but for dogs\"}]}, config)\n",
                "final_response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]}, config)\n",
                "\n",
                "print(final_response[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 메모리 액세스\n",
                "\n",
                "여러 가지 방법으로 에이전트의 단기 메모리(상태)에 액세스하고 수정할 수 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 도구에서 단기 메모리 읽기\n",
                "\n",
                "`ToolRuntime` 매개변수를 사용하여 도구에서 단기 메모리(상태)에 액세스할 수 있습니다.\n",
                "\n",
                "`tool_runtime` 매개변수는 도구 시그니처에서 숨겨져 있지만(모델이 볼 수 없음) 도구는 이를 통해 상태에 액세스할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent, AgentState\n",
                "from langchain.tools import tool, ToolRuntime\n",
                "\n",
                "class CustomState(AgentState):\n",
                "    user_id: str\n",
                "\n",
                "@tool\n",
                "def get_user_info(\n",
                "    runtime: ToolRuntime\n",
                ") -> str:\n",
                "    \"\"\"Look up user info.\"\"\"\n",
                "    user_id = runtime.state[\"user_id\"]\n",
                "    return \"User is John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_user_info],\n",
                "    state_schema=CustomState,\n",
                ")\n",
                "\n",
                "result = agent.invoke({\n",
                "    \"messages\": [{\"role\": \"user\", \"content\": \"look up user information\"}],\n",
                "    \"user_id\": \"user_123\"\n",
                "})\n",
                "\n",
                "print(result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 도구에서 단기 메모리 쓰기\n",
                "\n",
                "실행 중에 에이전트의 단기 메모리(상태)를 수정하려면 도구에서 직접 상태 업데이트를 반환할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.tools import tool, ToolRuntime\n",
                "from langchain.messages import ToolMessage\n",
                "from langchain.agents import create_agent, AgentState\n",
                "from langgraph.types import Command\n",
                "from pydantic import BaseModel\n",
                "\n",
                "class CustomState(AgentState):\n",
                "    user_name: str\n",
                "\n",
                "class CustomContext(BaseModel):\n",
                "    user_id: str\n",
                "\n",
                "@tool\n",
                "def update_user_info(\n",
                "    runtime: ToolRuntime[CustomContext, CustomState],\n",
                ") -> Command:\n",
                "    \"\"\"Look up and update user info.\"\"\"\n",
                "    user_id = runtime.context.user_id\n",
                "    name = \"John Smith\" if user_id == \"user_123\" else \"Unknown user\"\n",
                "    return Command(update={\n",
                "        \"user_name\": name,\n",
                "        \"messages\": [\n",
                "            ToolMessage(\n",
                "                \"Successfully looked up user information\",\n",
                "                tool_call_id=runtime.tool_call_id\n",
                "            )\n",
                "        ]\n",
                "    })\n",
                "\n",
                "@tool\n",
                "def greet(\n",
                "    runtime: ToolRuntime[CustomContext, CustomState]\n",
                ") -> str:\n",
                "    \"\"\"Use this to greet the user once you found their info.\"\"\"\n",
                "    user_name = runtime.state[\"user_name\"]\n",
                "    return f\"Hello {user_name}!\"\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[update_user_info, greet],\n",
                "    state_schema=CustomState,\n",
                "    context_schema=CustomContext,\n",
                ")\n",
                "\n",
                "result = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"greet the user\"}]},\n",
                "    context=CustomContext(user_id=\"user_123\"),\n",
                ")\n",
                "\n",
                "print(result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 프롬프트에서 메모리 액세스\n",
                "\n",
                "대화 기록이나 커스텀 상태 필드를 기반으로 동적 프롬프트를 생성하기 위해 미들웨어에서 단기 메모리(상태)에 액세스할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent\n",
                "from typing import TypedDict\n",
                "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
                "from langchain.tools import tool\n",
                "\n",
                "class CustomContext(TypedDict):\n",
                "    user_name: str\n",
                "\n",
                "@tool\n",
                "def get_weather(city: str) -> str:\n",
                "    \"\"\"Get the weather in a city.\"\"\"\n",
                "    return f\"The weather in {city} is always sunny!\"\n",
                "\n",
                "@dynamic_prompt\n",
                "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
                "    user_name = request.runtime.context[\"user_name\"]\n",
                "    system_prompt = f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
                "    return system_prompt\n",
                "\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[get_weather],\n",
                "    middleware=[dynamic_system_prompt],\n",
                "    context_schema=CustomContext,\n",
                ")\n",
                "\n",
                "result = agent.invoke(\n",
                "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
                "    context=CustomContext(user_name=\"John Smith\"),\n",
                ")\n",
                "\n",
                "print(result[\"messages\"][-1].content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 종합 예제\n",
                "\n",
                "다양한 메모리 관리 기법을 결합한 실용적인 예제입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_agent, AgentState\n",
                "from langchain.agents.middleware import SummarizationMiddleware, before_model\n",
                "from langchain.tools import tool, ToolRuntime\n",
                "from langgraph.checkpoint.memory import InMemorySaver\n",
                "from langgraph.runtime import Runtime\n",
                "from typing import Any\n",
                "\n",
                "# 커스텀 상태\n",
                "class ConversationState(AgentState):\n",
                "    user_preferences: dict\n",
                "    conversation_count: int\n",
                "\n",
                "# 도구 정의\n",
                "@tool\n",
                "def save_preference(\n",
                "    preference_key: str,\n",
                "    preference_value: str,\n",
                "    runtime: ToolRuntime\n",
                ") -> str:\n",
                "    \"\"\"Save user preference.\"\"\"\n",
                "    return f\"Saved preference: {preference_key} = {preference_value}\"\n",
                "\n",
                "# 메시지 트리밍 미들웨어\n",
                "@before_model\n",
                "def count_and_trim(state: ConversationState, runtime: Runtime) -> dict[str, Any] | None:\n",
                "    messages = state[\"messages\"]\n",
                "    count = state.get(\"conversation_count\", 0) + 1\n",
                "    \n",
                "    updates = {\"conversation_count\": count}\n",
                "    \n",
                "    if len(messages) > 10:\n",
                "        print(f\"Trimming messages (conversation #{count})\")\n",
                "        from langchain.messages import RemoveMessage\n",
                "        from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
                "        updates[\"messages\"] = [\n",
                "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
                "            messages[0],\n",
                "            *messages[-5:]\n",
                "        ]\n",
                "    \n",
                "    return updates\n",
                "\n",
                "# 에이전트 생성\n",
                "agent = create_agent(\n",
                "    model=model,\n",
                "    tools=[save_preference],\n",
                "    state_schema=ConversationState,\n",
                "    middleware=[\n",
                "        count_and_trim,\n",
                "        SummarizationMiddleware(\n",
                "            model=\"openai:gpt-4.1-mini\",\n",
                "            max_tokens_before_summary=5000,\n",
                "            messages_to_keep=10,\n",
                "        )\n",
                "    ],\n",
                "    checkpointer=InMemorySaver(),\n",
                ")\n",
                "\n",
                "# 테스트\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "result = agent.invoke(\n",
                "    {\n",
                "        \"messages\": [{\"role\": \"user\", \"content\": \"Hi! I prefer dark mode.\"}],\n",
                "        \"user_preferences\": {},\n",
                "        \"conversation_count\": 0\n",
                "    },\n",
                "    config\n",
                ")\n",
                "\n",
                "print(\"\\nFinal state:\")\n",
                "print(f\"Conversation count: {result.get('conversation_count', 0)}\")\n",
                "print(f\"Message count: {len(result['messages'])}\")\n",
                "print(f\"Last message: {result['messages'][-1].content}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
