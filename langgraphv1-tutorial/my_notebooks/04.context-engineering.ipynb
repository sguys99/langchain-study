{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## 4. Context Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6b509",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Initial issue : 2025.11.05 </div>\n",
    "<div style=\"text-align: right\"> last update : 2025.11.05 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a6c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f9ae4",
   "metadata": {},
   "source": [
    "**에이전트가 실패하는 이유**\n",
    "\n",
    "에이전트가 실패할 때는 일반적으로 에이전트 내부의 LLM 호출이 잘못된 작업을 수행하거나 예상대로 작동하지 않았기 때문입니다.    \n",
    "LLM은 다음 두 가지 이유 중 하나로 실패합니다:\n",
    "\n",
    "1. 기본 LLM이 충분히 능력이 없음\n",
    "2. \"올바른\" 컨텍스트가 LLM에 전달되지 않음\n",
    "\n",
    "대부분의 경우 실제로는 두 번째 이유가 에이전트의 신뢰성을 떨어뜨립니다.\n",
    "\n",
    "**Context Engineering**은 LLM이 작업을 완수할 수 있도록 올바른 형식으로 올바른 정보와 도구를 제공하는 것입니다.   \n",
    "이것이 AI 엔지니어의 가장 중요한 업무입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff84f3",
   "metadata": {},
   "source": [
    "### 컨텍스트의 종류\n",
    "\n",
    "\n",
    "에이전트는 세 가지 종류의 컨텍스트를 제어합니다:\n",
    "\n",
    "| 컨텍스트 타입 | 제어 대상 | 지속성 |\n",
    "|------------|---------|-------|\n",
    "| **Model Context** | 모델 호출에 들어가는 내용 (지시사항, 메시지 기록, 도구, 응답 형식) | Transient |\n",
    "| **Tool Context** | 도구가 액세스하고 생성하는 내용 (상태, 저장소, 런타임 컨텍스트에 읽기/쓰기) | Persistent |\n",
    "| **Life-cycle Context** | 모델 및 도구 호출 사이에 발생하는 작업 (요약, 가드레일, 로깅 등) | Persistent |\n",
    "\n",
    "**Transient Context**: LLM이 단일 호출에서 보는 내용. 상태에 저장된 내용을 변경하지 않고 메시지, 도구 또는 프롬프트를 수정할 수 있습니다.\n",
    "\n",
    "**Persistent Context**: 여러 턴에 걸쳐 상태에 저장되는 내용. 라이프사이클 훅과 도구 쓰기는 이를 영구적으로 수정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb3a8c",
   "metadata": {},
   "source": [
    "### 데이터 소스\n",
    "\n",
    "에이전트는 다양한 데이터 소스에 액세스(읽기/쓰기)합니다:\n",
    "\n",
    "| 데이터 소스 | 다른 이름 | 범위 | 예시 |\n",
    "|----------|---------|------|-----|\n",
    "| **Runtime Context** | 정적 구성 | 대화 범위 | 사용자 ID, API 키, DB 연결, 권한 |\n",
    "| **State** | 단기 메모리 | 대화 범위 | 현재 메시지, 업로드된 파일, 인증 상태 |\n",
    "| **Store** | 장기 메모리 | 대화 간 공유 | 사용자 선호도, 추출된 인사이트, 기록 데이터 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bee41",
   "metadata": {},
   "source": [
    "## Model Context\n",
    "\n",
    "각 모델 호출에 들어가는 내용을 제어합니다 - 지시사항, 사용 가능한 도구, 사용할 모델 및 출력 형식입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4474b",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "\n",
    "시스템 프롬프트는 LLM의 동작과 능력을 설정합니다. 다양한 사용자, 컨텍스트 또는 대화 단계에는 다양한 지시사항이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16054a4e",
   "metadata": {},
   "source": [
    "### Messages  \n",
    "\n",
    "메시지는 LLM에 전송되는 프롬프트를 구성합니다.  \n",
    "LLM이 올바른 정보를 가지고 잘 응답할 수 있도록 메시지 내용을 관리하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1688618",
   "metadata": {},
   "source": [
    "state에서 파일 컨텍스트 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6429f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelResponse, ModelRequest\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call # 모델 호출을 감싸는 미들웨어로 등록, 모델 호출 전후에 추가로직 실행\n",
    "def inject_file_context(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"사용자가 업로드한 파일 컨텍스트를 주입\"\"\"\n",
    "    # State에서 업로드된 파일 메타데이터 가져오기\n",
    "    uploaded_files = request.state.get(\"uploaded_files\", [])\n",
    "\n",
    "    if uploaded_files:\n",
    "        # 사용 가능한 파일에 대한 컨텍스트 구축\n",
    "        file_descriptions = []\n",
    "        for file in uploaded_files:\n",
    "            file_descriptions.append(\n",
    "                f\"- {file['name']} ({file['type']}): {file['summary']}\"\n",
    "            ) # 각 파일을 약속된 형식, 이름으로 변환?? (예: - report.pdf (PDF): 2024년 분기별 매출 보고서)\n",
    "\n",
    "        file_context = f\"\"\"Files you have access to in this conversation:\n",
    "{chr(10).join(file_descriptions)}\n",
    "\n",
    "Reference these files when answering questions.\"\"\" # 파일 컨텍시트 구성\n",
    "\n",
    "        # 최근 메시지 앞에 파일 컨텍스트 주입\n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": file_context},\n",
    "        ]\n",
    "        request = request.override(messages=messages)\n",
    "        # 기존 대화 메시지 뒤에 파일 정보를 user 메시지로 추가(LLM이 파일 존재를 인지하고 답변에 사용할 수 있게됨)\n",
    "\n",
    "    return handler(request) # 모델 호출 실행\n",
    "\n",
    "\n",
    "# 이렇게 하면 보고서 내용 요약해줘 질문에서 LLM은 어떤 보고서가 있는지 모르겠지만\n",
    "# 미들웨어를 적용하면 LLM이 파일을 인지하고 적절한 도구를 호출하거나 맥락을 고려한 답변 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25694c",
   "metadata": {},
   "source": [
    "실행 예시\n",
    "\n",
    "```python\n",
    "agent = create_agent(model=model, tools=[search_tool], middleware=[inject_file_context])\n",
    "\n",
    "# 파일이 업로드된 상태로 호출\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What files do I have?\"}],\n",
    "        \"uploaded_files\": [\n",
    "            {\"name\": \"report.pdf\", \"type\": \"PDF\", \"summary\": \"Q4 sales report\"},\n",
    "            {\"name\": \"data.csv\", \"type\": \"CSV\", \"summary\": \"Customer data\"},\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e43fd7",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "도구를 통해 모델이 데이터베이스, API 및 외부 시스템과 상호 작용할 수 있습니다.   \n",
    "도구를 정의하고 선택하는 방법은 모델이 작업을 효과적으로 완료할 수 있는지에 직접적인 영향을 미칩니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d31cfc",
   "metadata": {},
   "source": [
    "도구 정의\n",
    "\n",
    "- 각 도구에는 명확한 이름, 설명, 인수 이름 및 인수 설명이 필요합니다.   \n",
    "- 이것들은 단순한 메타데이터가 아니라 모델이 도구를 언제 어떻게 사용할지에 대한 추론을 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8617e86",
   "metadata": {},
   "source": [
    "```python\n",
    "@tool(parse_docstring=True)\n",
    "def search_orders(user_id: str, status: str, limit: int = 10) -> str:\n",
    "    \"\"\"Search for user orders by status.\n",
    "\n",
    "    Use this when the user asks about order history or wants to check\n",
    "    order status. Always filter by the provided status.\n",
    "\n",
    "    Args:\n",
    "        user_id: Unique identifier for the user\n",
    "        status: Order status: 'pending', 'shipped', or 'delivered'\n",
    "        limit: Maximum number of results to return\n",
    "    \"\"\"\n",
    "    return f\"Found orders for {user_id} with status {status} (limit: {limit})\"\n",
    "\n",
    "\n",
    "agent = create_agent(model=model, tools=[search_orders])\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Show me my pending orders for user_123\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb0567",
   "metadata": {},
   "source": [
    "State 기반 도구 선택\n",
    "\n",
    "대화 단계에 따라 사용 가능한 도구를 동적으로 조정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3f5fd",
   "metadata": {},
   "source": [
    "```python\n",
    "@tool\n",
    "def public_search(query: str) -> str:\n",
    "    \"\"\"Public search - available to all users.\"\"\"\n",
    "    return f\"Public results for: {query}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def private_search(query: str) -> str:\n",
    "    \"\"\"Private search - requires authentication.\"\"\"\n",
    "    return f\"Private results for: {query}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def advanced_search(query: str) -> str:\n",
    "    \"\"\"Advanced search - requires authentication and conversation history.\"\"\"\n",
    "    return f\"Advanced results for: {query}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f8441",
   "metadata": {},
   "source": [
    "```python\n",
    "@wrap_model_call\n",
    "def state_based_tools(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"대화 State에 따라 도구 필터링\"\"\"\n",
    "    state = request.state\n",
    "    is_authenticated = state.get(\"authenticated\", False)\n",
    "    message_count = len(state[\"messages\"])\n",
    "\n",
    "    # 인증되지 않은 경우 공개 도구만 활성화\n",
    "    if not is_authenticated:\n",
    "        tools = [t for t in request.tools if t.name == \"public_search\"]\n",
    "        request = request.override(tools=tools)\n",
    "    elif message_count < 5:\n",
    "        # 대화 초반에는 고급 도구 제한\n",
    "        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n",
    "        request = request.override(tools=tools)\n",
    "\n",
    "    return handler(request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea56426",
   "metadata": {},
   "source": [
    "```python\n",
    "# 인증되지 않은 사용자\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for Python tutorials\"}],\n",
    "        \"authenticated\": False,\n",
    "    }\n",
    ")\n",
    "print(\"Unauthenticated:\", result[\"messages\"][-1].content)\n",
    "\n",
    "# 인증된 사용자\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for Python tutorials\"}],\n",
    "        \"authenticated\": True,\n",
    "    }\n",
    ")\n",
    "print(\"\\nAuthenticated:\", result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04321f83",
   "metadata": {},
   "source": [
    "Runtime Context 기반 도구 선택   \n",
    "\n",
    "사용자 권한에 따라 도구를 필터링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8324f",
   "metadata": {},
   "source": [
    "```python\n",
    "@tool\n",
    "def read_data(table: str) -> str:\n",
    "    \"\"\"테이블에서 데이터를 읽어옵니다.\"\"\"\n",
    "    return f\"{table} 테이블에서 데이터를 읽었습니다.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_data(table: str) -> str:\n",
    "    \"\"\"테이블에 데이터를 작성합니다.\"\"\"\n",
    "    return f\"{table} 테이블에 데이터를 작성했습니다.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def delete_data(table: str, data_id: str) -> str:\n",
    "    \"\"\"테이블에서 데이터를 삭제합니다.\"\"\"\n",
    "    return f\"{table} 테이블에서 데이터를 삭제했습니다.\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserRole:\n",
    "    user_role: str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2aa4e",
   "metadata": {},
   "source": [
    "```python\n",
    "@wrap_model_call\n",
    "def context_based_tools(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Runtime Context 권한에 따라 도구 필터링\"\"\"\n",
    "    user_role = request.runtime.context.user_role\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        # 관리자는 모든 도구 사용 가능\n",
    "        pass\n",
    "    elif user_role == \"editor\":\n",
    "        # 편집자는 삭제 도구를 사용할 수 없습니다.\n",
    "        tools = [t for t in request.tools if t.name != \"delete_data\"]\n",
    "        request = request.override(tools=tools)\n",
    "    else:\n",
    "        # 뷰어는 읽기 전용 도구만 사용할 수 있습니다.\n",
    "        tools = [t for t in request.tools if t.name == \"read_data\"]\n",
    "        request = request.override(tools=tools)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[read_data, write_data, delete_data],\n",
    "    middleware=[context_based_tools],\n",
    "    context_schema=UserRole,\n",
    "    system_prompt=\"사용자의 요구사항을 바로 수행해 주세요. 주어진 도구를 사용해 주세요. 사용할 도구가 없다면, 권한이 없다고 답변하세요.\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd9215",
   "metadata": {},
   "source": [
    "```python\n",
    "# 뷰어\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"User 테이블을 조회하세요.\")]},\n",
    "    context=UserRole(user_role=\"viewer\"),\n",
    ")\n",
    "\n",
    "# 뷰어\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"User 테이블에서 abc 레코드를 삭제해 주세요\")]\n",
    "    },\n",
    "    context=UserRole(user_role=\"viewer\"),\n",
    ")\n",
    "# 관리자\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"User 테이블에서 abc 레코드를 삭제해 주세요\")]\n",
    "    },\n",
    "    context=UserRole(user_role=\"admin\"),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47f40b",
   "metadata": {},
   "source": [
    "Model   \n",
    "\n",
    "다양한 모델은 다양한 강점, 비용 및 컨텍스트 창을 가지고 있습니다. 작업에 적합한 모델을 선택하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f8c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 모델을 미들웨어 외부에서 한 번만 초기화\n",
    "large_model = init_chat_model(\"openai:gpt-4.1\")\n",
    "efficient_model = init_chat_model(\"openai:gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b69fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def state_based_model(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"대화 길이에 따라 모델 선택\"\"\"\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    if message_count > 10:\n",
    "        # 긴 대화 - 큰 컨텍스트 창을 가진 모델 사용\n",
    "        model = large_model\n",
    "        print(f\"Using large model for {message_count} messages\")\n",
    "    else:\n",
    "        # 짧은 대화 - 효율적인 모델 사용\n",
    "        model = efficient_model\n",
    "        print(f\"Using efficient model for {message_count} messages\")\n",
    "\n",
    "    request = request.override(model=model) # request의 모델 설정을 선택된 모델로 교체, 다른 설정은 그대로 유지\n",
    "    return handler(request) # 수정된 요청으로 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e9775",
   "metadata": {},
   "source": [
    "```python\n",
    "agent = create_agent(\n",
    "    model=efficient_model, tools=[search_tool], middleware=[state_based_model]\n",
    ")\n",
    "\n",
    "# 짧은 대화\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})\n",
    "print(result[\"messages\"][-1].content[:100])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d040a",
   "metadata": {},
   "source": [
    "Response format: 구조화된 출력은 비구조화된 텍스트를 검증된 구조화 데이터로 변환합니다. 특정 필드를 추출하거나 다운스트림 시스템을 위한 데이터를 반환할 때 자유 형식 텍스트로는 충분하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2dd149",
   "metadata": {},
   "source": [
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CustomerSupportTicket(BaseModel):\n",
    "    \"\"\"고객 메시지에서 추출된 구조화된 티켓 정보\"\"\"\n",
    "\n",
    "    category: str = Field(\n",
    "        description=\"Issue category: 'billing', 'technical', 'account', or 'product'\"\n",
    "    )\n",
    "    priority: str = Field(\n",
    "        description=\"Urgency level: 'low', 'medium', 'high', or 'critical'\"\n",
    "    )\n",
    "    summary: str = Field(description=\"One-sentence summary of the customer's issue\")\n",
    "    customer_sentiment: str = Field(\n",
    "        description=\"Customer's emotional tone: 'frustrated', 'neutral', or 'satisfied'\"\n",
    "    )\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model, tools=[search_tool], response_format=CustomerSupportTicket\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I can't login to my account! I've been trying for an hour and it keeps saying invalid credentials.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과는 CustomerSupportTicket 형식으로 반환됨\n",
    "print(\"Ticket:\", result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee85dd7",
   "metadata": {},
   "source": [
    "State 기반 Response format 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cbced5",
   "metadata": {},
   "source": [
    "```python\n",
    "class SimpleResponse(BaseModel):\n",
    "    \"\"\"초기 대화를 위한 간단한 응답\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"A brief answer\")\n",
    "\n",
    "\n",
    "class DetailedResponse(BaseModel):\n",
    "    \"\"\"확립된 대화를 위한 상세한 응답\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"A detailed answer\")\n",
    "    reasoning: str = Field(description=\"Explanation of reasoning\")\n",
    "    confidence: float = Field(description=\"Confidence score 0-1\")\n",
    "\n",
    "\n",
    "@wrap_model_call\n",
    "def state_based_output(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"State에 따라 출력 형식 선택\"\"\"\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    if message_count < 3:\n",
    "        # 초기 대화 - 간단한 형식 사용\n",
    "        request = request.override(response_format=SimpleResponse)\n",
    "    else:\n",
    "        # 확립된 대화 - 상세한 형식 사용\n",
    "        request = request.override(response_format=DetailedResponse)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "\n",
    "agent = create_agent(model=model, tools=[search_tool], middleware=[state_based_output])\n",
    "\n",
    "# 첫 번째 메시지 - 간단한 응답\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is Python?\"}]})\n",
    "print(\"Simple response:\", result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13656995",
   "metadata": {},
   "source": [
    "### Tool Context\n",
    "도구는 컨텍스트를 읽고 쓰는 두가지 작업을 모두 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d0158",
   "metadata": {},
   "source": [
    "Reads: State에서 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1768180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "\n",
    "@tool\n",
    "def check_authentication(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Check if user is authenticated.\"\"\"\n",
    "    # State에서 현재 인증 상태 확인\n",
    "    current_state = runtime.state\n",
    "    is_authenticated = current_state.get(\"authenticated\", False)\n",
    "\n",
    "    if is_authenticated:\n",
    "        return \"User is authenticated\"\n",
    "    else:\n",
    "        return \"User is not authenticated\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf3636",
   "metadata": {},
   "source": [
    "```python\n",
    "agent = create_agent(model=model, tools=[check_authentication])\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Am I authenticated?\"}],\n",
    "        \"authenticated\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45535a30",
   "metadata": {},
   "source": [
    "Reads: Store에서 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8cf9d",
   "metadata": {},
   "source": [
    "```python\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_preference(preference_key: str, runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Get user preference from Store.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "\n",
    "    # Store에서 기존 선호도 읽기\n",
    "    store = runtime.store\n",
    "    existing_prefs = store.get((\"preferences\",), user_id)\n",
    "\n",
    "    if existing_prefs:\n",
    "        value = existing_prefs.value.get(preference_key)\n",
    "        return (\n",
    "            f\"{preference_key}: {value}\"\n",
    "            if value\n",
    "            else f\"No preference set for {preference_key}\"\n",
    "        )\n",
    "    else:\n",
    "        return \"No preferences found\"\n",
    "\n",
    "\n",
    "store = InMemoryStore()\n",
    "store.put((\"preferences\",), \"user_123\", {\"theme\": \"dark\", \"language\": \"ko\"})\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model, tools=[get_preference], context_schema=Context, store=store\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my theme preference?\"}]},\n",
    "    context=Context(user_id=\"user_123\"),\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21b44f",
   "metadata": {},
   "source": [
    "writes: State에 쓰기  \n",
    "Writes: Store에 쓰기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c8201",
   "metadata": {},
   "source": [
    "### Life-cycle Context\n",
    "데이터 흐름을 가로채서 요약, 가드레일 및 로깅과 같은 교차 관심사 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1b5de",
   "metadata": {},
   "source": [
    "Summarization: 대화 기록이 길어질때 자동 압축. 오래된 메시지를 요역으로 영구 대체하여 향후 턴에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c716e",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_tool],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"openai:gpt-4.1-mini\",\n",
    "            max_tokens_before_summary=4000,  # 4000 토큰에서 요약 트리거\n",
    "            messages_to_keep=20,  # 요약 후 최근 20개 메시지 유지\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 대화가 길어지면 자동으로 요약됨\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about Python\"}]}\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content[:200])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed28375",
   "metadata": {},
   "source": [
    "## 종합 예제: 다층 컨택스트 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479d9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import (\n",
    "    dynamic_prompt,\n",
    "    wrap_model_call,\n",
    "    ModelRequest,\n",
    "    ModelResponse,\n",
    ")\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from typing import Callable\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4833019",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UserContext:\n",
    "    user_id: str\n",
    "    user_role: str\n",
    "    subscription_tier: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fc0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 정의\n",
    "@tool\n",
    "def get_user_history(runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Get user's search history.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    store = runtime.store\n",
    "\n",
    "    history = store.get((\"history\",), user_id)\n",
    "    if history:\n",
    "        return f\"Recent searches: {history.value.get('searches', [])}\"\n",
    "    return \"No history found\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_search(query: str, runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Save search query.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    store = runtime.store\n",
    "\n",
    "    # 기존 히스토리 가져오기\n",
    "    existing = store.get((\"history\",), user_id)\n",
    "    searches = existing.value.get(\"searches\", []) if existing else []\n",
    "\n",
    "    # 새 검색 추가\n",
    "    searches.append(query)\n",
    "    store.put((\"history\",), user_id, {\"searches\": searches[-5:]})\n",
    "\n",
    "    return f\"Saved: {query}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def advanced_analysis(data: str, runtime: ToolRuntime[UserContext]) -> str:\n",
    "    \"\"\"Perform advanced analysis (premium feature).\"\"\"\n",
    "    tier = runtime.context.subscription_tier\n",
    "    if tier != \"premium\":\n",
    "        return \"This feature requires a premium subscription\"\n",
    "    return f\"Advanced analysis results for: {data}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e04a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동적 시스템 프롬프트\n",
    "@dynamic_prompt\n",
    "def role_based_prompt(request: ModelRequest) -> str:\n",
    "    user_role = request.runtime.context.user_role\n",
    "    tier = request.runtime.context.subscription_tier\n",
    "\n",
    "    base = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        base += \" You have admin privileges.\"\n",
    "\n",
    "    if tier == \"premium\":\n",
    "        base += \" This user has premium features enabled.\"\n",
    "\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98708282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구독 등급에 따른 도구 필터링\n",
    "@wrap_model_call\n",
    "def tier_based_tools(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    tier = request.runtime.context.subscription_tier\n",
    "\n",
    "    if tier != \"premium\":\n",
    "        # 무료 사용자는 고급 분석 불가\n",
    "        tools = [t for t in request.tools if t.name != \"advanced_analysis\"]\n",
    "        request = request.override(tools=tools)\n",
    "\n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d37a3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 초기화\n",
    "store = InMemoryStore()\n",
    "store.put((\"history\",), \"user_001\", {\"searches\": [\"Python\", \"Machine Learning\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f97b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 생성\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_history, save_search, advanced_analysis],\n",
    "    middleware=[\n",
    "        role_based_prompt,\n",
    "        tier_based_tools,\n",
    "    ],\n",
    "    context_schema=UserContext,\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff6a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Premium User ===\n",
      "Your recent search history includes searches for \"Python\" and \"Machine Learning.\" Since I needed data from your history for the advanced analysis and it looks like it was done without input data, please let me know if you'd like me to perform the advanced analysis on your recent search topics or any other specific data you provide.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 1: 프리미엄 사용자\n",
    "print(\"=== Premium User ===\")\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Get my search history and perform advanced analysis\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    context=UserContext(\n",
    "        user_id=\"user_001\", user_role=\"admin\", subscription_tier=\"premium\"\n",
    "    ),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5eb5c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Free User ===\n",
      "Could you please specify the type of data you have and the kind of advanced analysis you would like me to perform? Also, if you could provide the data or describe its format, that would be helpful.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 2: 무료 사용자\n",
    "print(\"\\n=== Free User ===\")\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Perform advanced analysis on my data\"}]},\n",
    "    context=UserContext(user_id=\"user_002\", user_role=\"user\", subscription_tier=\"free\"),\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba6e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
