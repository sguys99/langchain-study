{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2550920c-09d8-48b3-be2f-b36362c37989",
   "metadata": {},
   "source": [
    "## 4. Context Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6b509",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Initial issue : 2025.11.05 </div>\n",
    "<div style=\"text-align: right\"> last update : 2025.11.05 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a6c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f9ae4",
   "metadata": {},
   "source": [
    "**에이전트가 실패하는 이유**\n",
    "\n",
    "에이전트가 실패할 때는 일반적으로 에이전트 내부의 LLM 호출이 잘못된 작업을 수행하거나 예상대로 작동하지 않았기 때문입니다.    \n",
    "LLM은 다음 두 가지 이유 중 하나로 실패합니다:\n",
    "\n",
    "1. 기본 LLM이 충분히 능력이 없음\n",
    "2. \"올바른\" 컨텍스트가 LLM에 전달되지 않음\n",
    "\n",
    "대부분의 경우 실제로는 두 번째 이유가 에이전트의 신뢰성을 떨어뜨립니다.\n",
    "\n",
    "**Context Engineering**은 LLM이 작업을 완수할 수 있도록 올바른 형식으로 올바른 정보와 도구를 제공하는 것입니다.   \n",
    "이것이 AI 엔지니어의 가장 중요한 업무입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff84f3",
   "metadata": {},
   "source": [
    "### 컨텍스트의 종류\n",
    "\n",
    "\n",
    "에이전트는 세 가지 종류의 컨텍스트를 제어합니다:\n",
    "\n",
    "| 컨텍스트 타입 | 제어 대상 | 지속성 |\n",
    "|------------|---------|-------|\n",
    "| **Model Context** | 모델 호출에 들어가는 내용 (지시사항, 메시지 기록, 도구, 응답 형식) | Transient |\n",
    "| **Tool Context** | 도구가 액세스하고 생성하는 내용 (상태, 저장소, 런타임 컨텍스트에 읽기/쓰기) | Persistent |\n",
    "| **Life-cycle Context** | 모델 및 도구 호출 사이에 발생하는 작업 (요약, 가드레일, 로깅 등) | Persistent |\n",
    "\n",
    "**Transient Context**: LLM이 단일 호출에서 보는 내용. 상태에 저장된 내용을 변경하지 않고 메시지, 도구 또는 프롬프트를 수정할 수 있습니다.\n",
    "\n",
    "**Persistent Context**: 여러 턴에 걸쳐 상태에 저장되는 내용. 라이프사이클 훅과 도구 쓰기는 이를 영구적으로 수정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb3a8c",
   "metadata": {},
   "source": [
    "### 데이터 소스\n",
    "\n",
    "에이전트는 다양한 데이터 소스에 액세스(읽기/쓰기)합니다:\n",
    "\n",
    "| 데이터 소스 | 다른 이름 | 범위 | 예시 |\n",
    "|----------|---------|------|-----|\n",
    "| **Runtime Context** | 정적 구성 | 대화 범위 | 사용자 ID, API 키, DB 연결, 권한 |\n",
    "| **State** | 단기 메모리 | 대화 범위 | 현재 메시지, 업로드된 파일, 인증 상태 |\n",
    "| **Store** | 장기 메모리 | 대화 간 공유 | 사용자 선호도, 추출된 인사이트, 기록 데이터 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bee41",
   "metadata": {},
   "source": [
    "## Model Context\n",
    "\n",
    "각 모델 호출에 들어가는 내용을 제어합니다 - 지시사항, 사용 가능한 도구, 사용할 모델 및 출력 형식입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4474b",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "\n",
    "시스템 프롬프트는 LLM의 동작과 능력을 설정합니다. 다양한 사용자, 컨텍스트 또는 대화 단계에는 다양한 지시사항이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16054a4e",
   "metadata": {},
   "source": [
    "### Messages  \n",
    "\n",
    "메시지는 LLM에 전송되는 프롬프트를 구성합니다.  \n",
    "LLM이 올바른 정보를 가지고 잘 응답할 수 있도록 메시지 내용을 관리하는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1688618",
   "metadata": {},
   "source": [
    "state에서 파일 컨텍스트 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6429f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelResponse, ModelRequest\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call # 모델 호출을 감싸는 미들웨어로 등록, 모델 호출 전후에 추가로직 실행\n",
    "def inject_file_context(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"사용자가 업로드한 파일 컨텍스트를 주입\"\"\"\n",
    "    # State에서 업로드된 파일 메타데이터 가져오기\n",
    "    uploaded_files = request.state.get(\"uploaded_files\", [])\n",
    "\n",
    "    if uploaded_files:\n",
    "        # 사용 가능한 파일에 대한 컨텍스트 구축\n",
    "        file_descriptions = []\n",
    "        for file in uploaded_files:\n",
    "            file_descriptions.append(\n",
    "                f\"- {file['name']} ({file['type']}): {file['summary']}\"\n",
    "            ) # 각 파일을 약속된 형식, 이름으로 변환?? (예: - report.pdf (PDF): 2024년 분기별 매출 보고서)\n",
    "\n",
    "        file_context = f\"\"\"Files you have access to in this conversation:\n",
    "{chr(10).join(file_descriptions)}\n",
    "\n",
    "Reference these files when answering questions.\"\"\" # 파일 컨텍시트 구성\n",
    "\n",
    "        # 최근 메시지 앞에 파일 컨텍스트 주입\n",
    "        messages = [\n",
    "            *request.messages,\n",
    "            {\"role\": \"user\", \"content\": file_context},\n",
    "        ]\n",
    "        request = request.override(messages=messages)\n",
    "        # 기존 대화 메시지 뒤에 파일 정보를 user 메시지로 추가(LLM이 파일 존재를 인지하고 답변에 사용할 수 있게됨)\n",
    "\n",
    "    return handler(request) # 모델 호출 실행\n",
    "\n",
    "\n",
    "# 이렇게 하면 보고서 내용 요약해줘 질문에서 LLM은 어떤 보고서가 있는지 모르겠지만\n",
    "# 미들웨어를 적용하면 LLM이 파일을 인지하고 적절한 도구를 호출하거나 맥락을 고려한 답변 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25694c",
   "metadata": {},
   "source": [
    "실행 예시\n",
    "\n",
    "```python\n",
    "agent = create_agent(model=model, tools=[search_tool], middleware=[inject_file_context])\n",
    "\n",
    "# 파일이 업로드된 상태로 호출\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What files do I have?\"}],\n",
    "        \"uploaded_files\": [\n",
    "            {\"name\": \"report.pdf\", \"type\": \"PDF\", \"summary\": \"Q4 sales report\"},\n",
    "            {\"name\": \"data.csv\", \"type\": \"CSV\", \"summary\": \"Customer data\"},\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e43fd7",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "도구를 통해 모델이 데이터베이스, API 및 외부 시스템과 상호 작용할 수 있습니다.   \n",
    "도구를 정의하고 선택하는 방법은 모델이 작업을 효과적으로 완료할 수 있는지에 직접적인 영향을 미칩니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d31cfc",
   "metadata": {},
   "source": [
    "도구 정의\n",
    "\n",
    "- 각 도구에는 명확한 이름, 설명, 인수 이름 및 인수 설명이 필요합니다.   \n",
    "- 이것들은 단순한 메타데이터가 아니라 모델이 도구를 언제 어떻게 사용할지에 대한 추론을 안내합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8617e86",
   "metadata": {},
   "source": [
    "```python\n",
    "@tool(parse_docstring=True)\n",
    "def search_orders(user_id: str, status: str, limit: int = 10) -> str:\n",
    "    \"\"\"Search for user orders by status.\n",
    "\n",
    "    Use this when the user asks about order history or wants to check\n",
    "    order status. Always filter by the provided status.\n",
    "\n",
    "    Args:\n",
    "        user_id: Unique identifier for the user\n",
    "        status: Order status: 'pending', 'shipped', or 'delivered'\n",
    "        limit: Maximum number of results to return\n",
    "    \"\"\"\n",
    "    return f\"Found orders for {user_id} with status {status} (limit: {limit})\"\n",
    "\n",
    "\n",
    "agent = create_agent(model=model, tools=[search_orders])\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Show me my pending orders for user_123\"}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb0567",
   "metadata": {},
   "source": [
    "State 기반 도구 선택\n",
    "\n",
    "대화 단계에 따라 사용 가능한 도구를 동적으로 조정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3f5fd",
   "metadata": {},
   "source": [
    "```python\n",
    "@tool\n",
    "def public_search(query: str) -> str:\n",
    "    \"\"\"Public search - available to all users.\"\"\"\n",
    "    return f\"Public results for: {query}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def private_search(query: str) -> str:\n",
    "    \"\"\"Private search - requires authentication.\"\"\"\n",
    "    return f\"Private results for: {query}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def advanced_search(query: str) -> str:\n",
    "    \"\"\"Advanced search - requires authentication and conversation history.\"\"\"\n",
    "    return f\"Advanced results for: {query}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f8441",
   "metadata": {},
   "source": [
    "```python\n",
    "@wrap_model_call\n",
    "def state_based_tools(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"대화 State에 따라 도구 필터링\"\"\"\n",
    "    state = request.state\n",
    "    is_authenticated = state.get(\"authenticated\", False)\n",
    "    message_count = len(state[\"messages\"])\n",
    "\n",
    "    # 인증되지 않은 경우 공개 도구만 활성화\n",
    "    if not is_authenticated:\n",
    "        tools = [t for t in request.tools if t.name == \"public_search\"]\n",
    "        request = request.override(tools=tools)\n",
    "    elif message_count < 5:\n",
    "        # 대화 초반에는 고급 도구 제한\n",
    "        tools = [t for t in request.tools if t.name != \"advanced_search\"]\n",
    "        request = request.override(tools=tools)\n",
    "\n",
    "    return handler(request)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea56426",
   "metadata": {},
   "source": [
    "```python\n",
    "# 인증되지 않은 사용자\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for Python tutorials\"}],\n",
    "        \"authenticated\": False,\n",
    "    }\n",
    ")\n",
    "print(\"Unauthenticated:\", result[\"messages\"][-1].content)\n",
    "\n",
    "# 인증된 사용자\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for Python tutorials\"}],\n",
    "        \"authenticated\": True,\n",
    "    }\n",
    ")\n",
    "print(\"\\nAuthenticated:\", result[\"messages\"][-1].content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04321f83",
   "metadata": {},
   "source": [
    "Runtime Context 기반 도구 선택   \n",
    "\n",
    "사용자 권한에 따라 도구를 필터링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8324f",
   "metadata": {},
   "source": [
    "```python\n",
    "@tool\n",
    "def read_data(table: str) -> str:\n",
    "    \"\"\"테이블에서 데이터를 읽어옵니다.\"\"\"\n",
    "    return f\"{table} 테이블에서 데이터를 읽었습니다.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_data(table: str) -> str:\n",
    "    \"\"\"테이블에 데이터를 작성합니다.\"\"\"\n",
    "    return f\"{table} 테이블에 데이터를 작성했습니다.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def delete_data(table: str, data_id: str) -> str:\n",
    "    \"\"\"테이블에서 데이터를 삭제합니다.\"\"\"\n",
    "    return f\"{table} 테이블에서 데이터를 삭제했습니다.\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserRole:\n",
    "    user_role: str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2aa4e",
   "metadata": {},
   "source": [
    "```python\n",
    "@wrap_model_call\n",
    "def context_based_tools(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"Runtime Context 권한에 따라 도구 필터링\"\"\"\n",
    "    user_role = request.runtime.context.user_role\n",
    "\n",
    "    if user_role == \"admin\":\n",
    "        # 관리자는 모든 도구 사용 가능\n",
    "        pass\n",
    "    elif user_role == \"editor\":\n",
    "        # 편집자는 삭제 도구를 사용할 수 없습니다.\n",
    "        tools = [t for t in request.tools if t.name != \"delete_data\"]\n",
    "        request = request.override(tools=tools)\n",
    "    else:\n",
    "        # 뷰어는 읽기 전용 도구만 사용할 수 있습니다.\n",
    "        tools = [t for t in request.tools if t.name == \"read_data\"]\n",
    "        request = request.override(tools=tools)\n",
    "\n",
    "    return handler(request)\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[read_data, write_data, delete_data],\n",
    "    middleware=[context_based_tools],\n",
    "    context_schema=UserRole,\n",
    "    system_prompt=\"사용자의 요구사항을 바로 수행해 주세요. 주어진 도구를 사용해 주세요. 사용할 도구가 없다면, 권한이 없다고 답변하세요.\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd9215",
   "metadata": {},
   "source": [
    "```python\n",
    "# 뷰어\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"User 테이블을 조회하세요.\")]},\n",
    "    context=UserRole(user_role=\"viewer\"),\n",
    ")\n",
    "\n",
    "# 뷰어\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"User 테이블에서 abc 레코드를 삭제해 주세요\")]\n",
    "    },\n",
    "    context=UserRole(user_role=\"viewer\"),\n",
    ")\n",
    "# 관리자\n",
    "stream_graph(\n",
    "    agent,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"User 테이블에서 abc 레코드를 삭제해 주세요\")]\n",
    "    },\n",
    "    context=UserRole(user_role=\"admin\"),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47f40b",
   "metadata": {},
   "source": [
    "Model   \n",
    "\n",
    "다양한 모델은 다양한 강점, 비용 및 컨텍스트 창을 가지고 있습니다. 작업에 적합한 모델을 선택하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f8c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 모델을 미들웨어 외부에서 한 번만 초기화\n",
    "large_model = init_chat_model(\"openai:gpt-4.1\")\n",
    "efficient_model = init_chat_model(\"openai:gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b69fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def state_based_model(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    \"\"\"대화 길이에 따라 모델 선택\"\"\"\n",
    "    message_count = len(request.messages)\n",
    "\n",
    "    if message_count > 10:\n",
    "        # 긴 대화 - 큰 컨텍스트 창을 가진 모델 사용\n",
    "        model = large_model\n",
    "        print(f\"Using large model for {message_count} messages\")\n",
    "    else:\n",
    "        # 짧은 대화 - 효율적인 모델 사용\n",
    "        model = efficient_model\n",
    "        print(f\"Using efficient model for {message_count} messages\")\n",
    "\n",
    "    request = request.override(model=model) # request의 모델 설정을 선택된 모델로 교체, 다른 설정은 그대로 유지\n",
    "    return handler(request) # 수정된 요청으로 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e9775",
   "metadata": {},
   "source": [
    "```python\n",
    "agent = create_agent(\n",
    "    model=efficient_model, tools=[search_tool], middleware=[state_based_model]\n",
    ")\n",
    "\n",
    "# 짧은 대화\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]})\n",
    "print(result[\"messages\"][-1].content[:100])\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d040a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
