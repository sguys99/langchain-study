import streamlit as st
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain import hub
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from llm import get_ai_response
load_dotenv()



st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon=":robot_face:") 
st.title("ğŸ¤– ì†Œë“ì„¸ ì±—ë´‡")  
st.caption("ì†Œë“ì„¸ì— ê´€ë ¨ëœ ëª¨ë“  ê²ƒì„ ë‹µí•´ë“œë¦½ë‹ˆë‹¤.")


if "message_list" not in st.session_state:
    st.session_state["message_list"] = []


for message in st.session_state["message_list"]:
    with st.chat_message(message["role"]):
        st.write(message["content"])

if user_question := st.chat_input(placeholder="ì†Œë“ì„¸ì— ê´€ë ¨ëœ ê¶ê¸ˆí•œ ë‚´ìš©ë“¤ì„ ë§ì”€í•´ ì£¼ì„¸ìš”!"):
    with st.chat_message("user"):
        st.write(user_question)
    st.session_state["message_list"].append({"role": "user", "content": user_question})
    
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤."):
        ai_response = get_ai_response(user_question)
        with st.chat_message("ai"):
            ai_message = st.write_stream(ai_response)
        st.session_state["message_list"].append({"role": "ai", "content": ai_message})