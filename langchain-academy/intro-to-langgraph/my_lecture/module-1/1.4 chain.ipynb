{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Chain\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 concepts.\n",
    "\n",
    "* Using [chat messages](https://docs.langchain.com/oss/python/langchain/messages) as our graph state\n",
    "* Using [chat models](https://docs.langchain.com/oss/python/integrations/chat) in graph nodes\n",
    "* [Binding tools](https://docs.langchain.com/oss/python/langchain/models#tool-calling) to our chat model\n",
    "* [Executing tool calls](https://docs.langchain.com/oss/python/langchain/models#tool-execution-loop) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Messages\n",
    "\n",
    "챗 모델은 대화 내 다양한 역할을 포착하는 [메시지](https://docs.langchain.com/oss/python/langchain/messages)를 사용할 수 있습니다. \n",
    "\n",
    "LangChain은 `HumanMessage`, `AIMessage`, `SystemMessage`, `ToolMessage` 등 다양한 메시지 유형을 지원합니다.\n",
    "\n",
    "이들은 각각 사용자의 메시지, 챗 모델의 메시지, 챗 모델의 행동 지시 메시지, 도구 호출 메시지를 나타냅니다.\n",
    "\n",
    "메시지 목록을 생성해 보겠습니다. \n",
    "\n",
    "각 메시지에는 다음 정보가 포함될 수 있습니다:\n",
    "\n",
    "* `content` - 메시지 내용\n",
    "* `name` - 메시지 작성자(option)\n",
    "* `response_metadata` - 메타데이터 딕셔너리(예: `AIMessages`의 경우 모델 제공자가 자주 채움, option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "그러니까 해양 포유류를 연구하고 있다고 하셨나요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "예. 맞습니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "좋아요, 무엇을 배우고 싶으신가요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "미국에서 범고래를 관찰하기 가장 좋은 장소에 대해 알고 싶습니다.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"그러니까 해양 포유류를 연구하고 있다고 하셨나요?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"예. 맞습니다.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"좋아요, 무엇을 배우고 싶으신가요?\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"미국에서 범고래를 관찰하기 가장 좋은 장소에 대해 알고 싶습니다.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Chat Models\n",
    "\n",
    "챗 모델은 위에서 논의한 바와 같이 메시지 시퀀스를 입력으로 사용하며 메시지 유형을 지원합니다.\n",
    "\n",
    "선택할 수 있는 모델이 [많습니다](https://docs.langchain.com/oss/python/integrations/chat)! OpenAI와 함께 작업해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='미국에서 범고래를 관찰하기 좋은 장소는 여러 곳이 있습니다. 그 중 일부는 다음과 같습니다:\\n\\n1. **알래스카**: 알래스카 근해에서는 범고래의 주요 서식지가 있습니다. 특히, 카트마이즈 해협이나 딘 섬 근처에서 범고래를 관찰할 수 있습니다.\\n\\n2. **워싱턴주**: 특히, 오레곤 성역 제도 주변의 퓨젯 사운드(Puget Sound) 지역에서 범고래를 관찰할 수 있습니다. 퓨젯 사운드에서는 범고래가 자주 나타납니다. 특히 \"Southern Resident\" 범고래 팩이 이 지역에서 자주 발견됩니다.\\n\\n3. **캘리포니아**: 몬터레이 베이(Monterey Bay)와 같은 곳에서도 범고래를 관찰할 수 있습니다. 이곳에서는 여름과 가을에 범고래가 많이 나타납니다.\\n\\n4. **하와이**: 하와이에서는 겨울철에 범고래의 Migration이 이루어지며, 하와이섬 주변에서 관찰할 수 있습니다.\\n\\n각 지역에서의 범고래 관찰은 계절 및 환경에 따라 달라질 수 있으므로 방문 시기를 잘 계획하는 것이 중요합니다. 추가 정보가 필요하시면 언제든지 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 299, 'prompt_tokens': 79, 'total_tokens': 378, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd4be55b21', 'id': 'chatcmpl-DA90zmMdXRvgVnPQV9DzjBAdAXLsx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c6a52-450d-7681-a96e-c2d606882348-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 79, 'output_tokens': 299, 'total_tokens': 378, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 299,\n",
       "  'prompt_tokens': 79,\n",
       "  'total_tokens': 378,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_provider': 'openai',\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_bd4be55b21',\n",
       " 'id': 'chatcmpl-DA90zmMdXRvgVnPQV9DzjBAdAXLsx',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Tools\n",
    "\n",
    "도구는 모델이 외부 시스템과 상호작용해야 할 때 유용합니다.\n",
    "\n",
    "외부 시스템(예: API)은 자연어 대신 특정 입력 스키마나 페이로드를 요구하는 경우가 많습니다.\n",
    "\n",
    "예를 들어 API를 도구로 바인딩하면, 모델이 필요한 입력 스키마를 인식하도록 합니다.\n",
    "\n",
    "모델은 사용자의 자연어 입력을 기반으로 도구를 호출할지 선택합니다. \n",
    "\n",
    "그리고 해당 도구의 스키마를 준수하는 출력을 반환합니다.\n",
    "\n",
    "[많은 LLM 제공업체가 도구 호출을 지원하며](https://docs.langchain.com/oss/python/integrations/chat) LangChain의 [도구 호출 인터페이스](https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/)는 간단합니다. \n",
    " \n",
    "Python `function`을 `ChatModel.bind_tools(function)` 형태로 전달하기만 하면 됩니다.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "입력값(예: `“2에 3을 곱하면 얼마인가요?”`)을 전달하면 도구 호출이 반환됩니다.\n",
    "\n",
    "도구 호출에는 호출할 함수 이름과 함께 함수의 입력 스키마에 맞는 특정 인수가 포함됩니다.\n",
    "\n",
    "```\n",
    "{‘arguments’: ‘{“a”:2,“b”:3}’, ‘name’: ‘multiply’}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"곱하기 3은 얼마입니까?\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 3},\n",
       "  'id': 'call_zTOSzLePSekYNXuGvZYOdCeD',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6202a6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 64, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_2d82c05f26', 'id': 'chatcmpl-DA9142VW4gl9hTfuIjZ3A2Z3DnomD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c6a52-5826-7393-8b4d-637a9b3df42f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'call_zTOSzLePSekYNXuGvZYOdCeD', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 64, 'output_tokens': 17, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using messages as state\n",
    "\n",
    "이러한 기반이 마련되었으므로 이제 그래프 state에서 [메시지](https://docs.langchain.com/oss/python/langchain/overview#messages)를 사용할 수 있습니다.\n",
    "\n",
    "`MessagesState` 상태를 단일 키 `messages`를 가진 `TypedDict`로 정의해 보겠습니다.\n",
    "\n",
    "`messages`는 위에서 정의한 대로 단순히 메시지 목록입니다(예: `HumanMessage` 등)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reducers\n",
    "\n",
    "문제가 생겼습니다!\n",
    "\n",
    "앞서 논의한 대로, 각 노드는 상태 키 `messages`에 대한 새 값을 반환합니다.\n",
    "\n",
    "하지만 이 새 값이 기존 `messages` 값을 덮어쓸 것입니다!\n",
    " \n",
    "그래프가 실행될 때, 우리는 `messages` 상태 키에 메시지를 **추가**하고 싶습니다.\n",
    " \n",
    "이를 해결하기 위해 [리듀서 함수](https://docs.langchain.com/oss/python/langgraph/graph-api#reducers)를 사용할 수 있습니다.\n",
    "\n",
    "리듀서는 상태 업데이트가 수행되는 방식을 지정합니다.\n",
    "\n",
    "리듀서 함수가 지정되지 않으면, 앞서 본 것처럼 키에 대한 업데이트가 *키를 덮어쓰는* 것으로 간주됩니다.\n",
    " \n",
    "하지만 메시지를 추가하려면 미리 구축된 `add_messages` 리듀서를 사용할 수 있습니다.\n",
    "\n",
    "이렇게 하면 모든 메시지가 기존 메시지 목록에 추가됩니다.\n",
    "\n",
    "`messages` 키에 `add_messages` 리듀서 함수를 메타데이터로 주석 처리하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "그래프 상태에 메시지 목록을 포함하는 것이 매우 흔하기 때문에, LangGraph에는 미리 구축된 [`MessagesState`](https://docs.langchain.com/oss/python/langgraph/graph-api#messagesstate)가 있습니다! \n",
    "\n",
    "`MessagesState`는 다음과 같이 정의됩니다:\n",
    "\n",
    "* 미리 구축된 단일 `messages` 키로 구성\n",
    "* `AnyMessage` 객체들의 리스트 형태\n",
    "* `add_messages` 리듀서를 사용\n",
    "\n",
    "위에서 보여준 것처럼 커스텀 `TypedDict`를 정의하는 것보다 덜 장황하기 때문에 일반적으로 `MessagesState`를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # 여기에 추가 키를 정의할 수도 있음\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "좀 더 깊이 들어가서, `add_messages` 리듀서가 독립적으로 어떻게 작동하는지 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='e2ae0775-5a1a-4a24-94ac-0171b60cc36b', tool_calls=[], invalid_tool_calls=[]),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='ab8823f4-96c3-4393-854a-e172dd9bac73'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='a07bf0f6-5083-4011-b6cc-f22cf0e4d0b1', tool_calls=[], invalid_tool_calls=[])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_Er4gChFoSGzU7lsuaGzfSGTQ)\n",
      " Call ID: call_Er4gChFoSGzU7lsuaGzfSGTQ\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
