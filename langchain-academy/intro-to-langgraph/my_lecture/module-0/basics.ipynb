{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "LangChain에서는 대규모 언어 모델(LLM) 애플리케이션을 쉽게 구축할 수 있도록 하는 것을 목표로 합니다. 구축 가능한 LLM 애플리케이션 유형 중 하나는 에이전트입니다. 에이전트 구축은 이전에는 불가능했던 다양한 작업을 자동화할 수 있기 때문에 많은 관심을 받고 있습니다. \n",
    "\n",
    "하지만 실제로는 이러한 작업을 안정적으로 수행하는 시스템을 구축하는 것이 매우 어렵습니다. 사용자와 함께 에이전트를 실제 운영 환경에 적용해 본 경험을 통해, 더 많은 제어 기능이 필요하다는 점을 깨달았습니다. 에이전트가 항상 특정 도구를 먼저 호출하도록 하거나 상태에 따라 다른 프롬프트를 사용하도록 설정해야 할 수 있습니다. \n",
    "\n",
    "이 문제를 해결하기 위해 우리는 에이전트 및 다중 에이전트 애플리케이션 구축을 위한 프레임워크인 [LangGraph](https://docs.langchain.com/oss/python/langgraph/overview)를 개발했습니다. LangChain 패키지와 별개로, LangGraph의 핵심 설계 철학은 개발자가 실제 시스템의 복잡성에 적합한 정밀도와 제어력을 에이전트 워크플로우에 더할 수 있도록 돕는 것입니다.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "본 과정은 일련의 모듈로 구성되어 있으며, 각 모듈은 LangGraph와 관련된 특정 주제에 초점을 맞춥니다. 각 모듈별로 폴더가 생성되며, 해당 폴더에는 일련의 노트북이 포함되어 있습니다. 각 노트북에는 개념을 단계별로 안내하는 동영상이 함께 제공되지만, 노트북 자체도 독립적으로 작동합니다. 즉, 설명이 포함되어 있어 동영상 없이도 볼 수 있습니다. 각 모듈 폴더에는 `studio` 폴더도 포함되어 있으며, 여기에는 LangGraph 애플리케이션 구축용 IDE인 [LangSmith Studio](https://docs.langchain.com/langsmith/quick-start-studio)에 로드할 수 있는 그래프 세트가 들어 있습니다.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "이 과정에서는 메시지 시퀀스를 입력으로 받아 메시지를 출력으로 반환하는 채팅 모델을 사용할 것입니다. LangChain은 [타사 통합](https://docs.langchain.com/oss/python/integrations/chat)을 통해 다양한 모델을 지원합니다. 기본적으로 본 과정에서는 널리 사용되며 성능이 우수한 [ChatOpenAI](https://docs.langchain.com/oss/python/integrations/chat/openai)를 사용할 예정입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langchain_openai langchain_core langchain_community langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "챗 모델에는 설정 가능한 [몇 가지 표준 매개변수](https://docs.langchain.com/oss/python/langchain/models#parameters)가 있습니다. 가장 흔히 사용되는 두 가지는 다음과 같습니다:\n",
    "\n",
    "* `model`: 모델 이름\n",
    "* `temperature`: 샘플링 온도\n",
    "\n",
    "`Temperature`는 모델 출력의 무작위성 또는 창의성을 제어합니다. 낮은 온도(0에 가까울수록)는 더 결정론적이고 집중된 출력을 생성합니다. 정확성이나 사실적인 응답이 필요한 작업에 적합합니다. 높은 온도(1에 가까울수록)는 창의적인 작업이나 다양한 응답 생성에 적합합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19a54d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "LangChain의 채팅 모델은 여러 [기본 메서드](https://reference.langchain.com/python/langchain_core/runnables)를 제공합니다. 주로 다음과 같은 메서드를 사용할 것입니다:\n",
    "\n",
    "* [stream](https://docs.langchain.com/oss/python/langchain/models#stream): 응답을 청크 단위로 스트리밍하여 반환\n",
    "* [invoke](https://docs.langchain.com/oss/python/langchain/models#invoke): 입력에 대해 체인을 호출\n",
    "\n",
    "또한 앞서 언급했듯이, 채팅 모델은 [messages](https://docs.langchain.com/oss/python/langchain/messages)를 입력으로 받습니다. 메시지는 발신자를 나타내는 역할(role)과 내용(content) 속성을 가집니다. 이에 대해서는 나중에 자세히 다루겠지만, 여기서는 기본적인 내용만 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1280e1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 14, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ed36a96f3d', 'id': 'chatcmpl-D9k41O6YBh7VEa9tJMF9th7DkmRZ3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c649a-cf7f-7930-aca5-73cc98889f29-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 10, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"안녕하세요.\", name=\"유광명\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "gpt4o_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "모델을 실행하면 `AIMessage` 응답을 받습니다.   \n",
    "문자열로 채팅 모델을 호출할 수 있다는 점에 유의하세요.   \n",
    "문자열이 입력으로 전달되면 `HumanMessage`로 변환된 후 기본 모델로 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ed36a96f3d', 'id': 'chatcmpl-D9k59VMsHHorVMt9osmLSq7Y4CGN5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c649b-e199-7533-bcb0-98916c158313-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_chat.invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Search Tools\n",
    "\n",
    "README에서 [Tavily](https://tavily.com/)도 확인할 수 있습니다. 이는 대규모 언어 모델(LLM)과 RAG(Retrieval-Augmented Generation)에 최적화된 검색 엔진으로, 효율적이고 신속하며 지속적인 검색 결과를 목표로 합니다. 앞서 언급했듯이 가입이 간편하며 무료 이용권도 넉넉하게 제공됩니다. 일부 강의(모듈 4)에서는 기본적으로 Tavily를 사용하지만, 코드를 직접 수정하고 싶다면 다른 검색 도구도 물론 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch  # updated at 1.0\n",
    "\n",
    "tavily_search = TavilySearch(max_results=3)\n",
    "\n",
    "data = tavily_search.invoke({\"query\": \"랭그래프가 뭐야?\"})\n",
    "search_docs = data.get(\"results\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://brunch.co.kr/@aideveloper/132',\n",
       "  'title': '23화 22. LangGraph 기본과 응용 - 브런치',\n",
       "  'content': 'LangGraph(랭그래프)는 LangChain(랭체인)을 기반으로 하는 에이전트 프레임워크입니다. LangGraph(랭그래프)의 주요 특징은 복잡한 제어구조를 가진 워크플로우를 유연하게 표현할 수 있다는 점입니다. 반면에 LangGraph(랭그래프)는 체인뿐만 아니라 일반적인 그래프 구조를 사용하여 복잡한 제어구조를 표현할 수 있습니다. LangGraph(랭그래프)는 노드와 엣지를 결합하여 멀티 에이전트 구현에 적합한 워크플로우를 표현합니다. 예를 들어, 아래 그림은 LangGraph(랭그래프)를 사용하여 소프트웨어 개발팀을 멀티에이전트로 구현하는 그래프입니다. 개발자는 LangGraph(랭그래프)를 사용하여 다양한 워크플로우를 그래프로 정의할 수 있습니다. LangGraph(랭그래프)는 에이전트 시스템에 국한되지 않고, 범용 워크플로우를 정의하는데 사용할 수 있습니다. 이 때문에 LangGraph(랭그래프)의 그래프를 상태그래프(StateGraph)라고도 합니다. LangGraph(랭그래프)는 각 노드의 처리를 Python함수 또는 Runnable객체로 정의합니다. 그 경우 LangGraph(랭그래프)의 사양에 따라 상태를 인수로 받아야 합니다. LangGraph(랭그래프)에서는 조건에 따라 노드간의 전환을 제어할 수 있습니다. StateGraph클래스를 사용하여 이 상태 그래프를 정의합니다. 이번에는 LangGraph(랭그래프)를 사용하여 대표적인 에이전트 아키텍처를 구현하는 방법을 소개합니다. LangGraph(랭그래프)를 사용하여 자연어 쉘 인터페이스를 사용하여 단일 에이전트를 구축하는 방법을 소개합니다. 이제 LangGraph(랭그래프)를 사용하여 이 자연어 쉘 인터페이스를 구현해 보겠습니다. LangGraph(랭그래프)를 사용하여 수평 아키텍처에서 에이전트 간의 대화방법을 구현하는 방법을 소개합니다. LangGraph(랭그래프)를 사용하여 여러 에이전트가 협력하여 소프트웨어 개발을 수행하는 시나리오를 구현합니다. LangGraph(랭그래프)나 LangChain(랭체인)외에 subprocess모듈이나 jsonschema모듈등을 추가하고 있습니다.',\n",
       "  'score': 0.79692537,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://lsjsj92.tistory.com/696',\n",
       "  'title': '랭그래프(LangGraph)란? LangGraph의 개념과 사용 방법 예제 ...',\n",
       "  'content': '특히 LangGraph의 핵심 구성 요소인 상태(State), 노드(Node), 엣지(Edge)에 대해 자세히 살펴보고, LLM을 연동하여 간단한 챗봇 에이전트(Agent)를 만들어보는 예제 코드를 살펴봅니다. def chatbot_node(state: AgentState): \"\"\" 현재 상태(대화 기록)를 기반으로 LLM을 호출하여 응답을 생성하는 노드입니다. response = llm.invoke(messages) # 받은 응답(AIMessage)을 상태의 messages 리스트에 추가하여 반환합니다. from langgraph.graph import StateGraph, END # StateGraph에 위에서 정의한 상태(AgentState)를 연결하여 그래프 빌더를 생성합니다. graph_builder.add_node(\"chatbot\", chatbot_node) # 그래프의 진입점(Entry Point)과 종료점(End Point)을 설정합니다. graph_builder.add_edge(\"chatbot\", END) # 정의된 내용으로 그래프를 컴파일하여 실행 가능한 앱을 만듭니다. 4. graph\\\\_builder.add\\\\_edge(\"chatbot\", END): \"chatbot\" 노드의 작업이 끝나면, 더 이상 다른 노드로 가지 않고 그래프 실행을 종료(END)하라고 엣지를 연결합니다. 이수진이라고 합니다.\")], \"turn_count\": 0 } # agent_app.invoke()를 사용하여 그래프를 실행합니다. print(\"\\\\n--- 최종 대화 기록 ---\") for message in final_state[\\'messages\\']: if isinstance(message, HumanMessage): print(f\"사용자: {message.content}\") elif isinstance(message, AIMessage): print(f\"AI 응답: {message.content}\"). 2. chatbot\\\\_node는 llm.invoke()를 통해 vLLM 서버에 요청을 보내고 응답을 받습니다. 이번 포스팅에서는 LangGraph의 핵심 개념과 간단한 예제를 통해 복잡한 LLM 에이전트를 어떻게 제어할 수 있는지 알아보았습니다. :   Agent, aiagent, langchain, langgraph, LLM, openai, RAG, vllm, 랭그래프, 랭체인.',\n",
       "  'score': 0.7446563,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://wikidocs.net/261577',\n",
       "  'title': '1-1. 랭그래프 LangGraph 소개 - 위키독스',\n",
       "  'content': 'LangGraph는 자연어 처리와 AI 응용 프로그램 개발을 위한 강력한 프레임워크로, 복잡한 언어 모델과의 상호작용을 효율적이고 구조화된 방식으로 구현할 수 있도록 돕',\n",
       "  'score': 0.46101677,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7545f4-aeb7-4b03-91f5-df3e021fe960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
